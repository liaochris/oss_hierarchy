{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7353ca-7a0a-49bf-b138-d7ea242d1972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252286ad-d984-4fb0-8e31-b0da5354bee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from source.lib.helpers import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac22f5f-f1a9-425a-b0af-6c29cf722dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightedQuantile(values, weights, quantiles):\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    sorter = np.argsort(values)\n",
    "    values = values[sorter]\n",
    "    weights = weights[sorter]\n",
    "    cumulative_weight = np.cumsum(weights)\n",
    "    total_weight = cumulative_weight[-1]\n",
    "    return np.interp(np.array(quantiles) * total_weight, cumulative_weight, values)\n",
    "\n",
    "def Assign3Bin(repo):\n",
    "    val = base_wm[repo]\n",
    "    if val <= q33:\n",
    "        return 0\n",
    "    elif val <= q67:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c2fea2-4a49-46d8-a20c-4a79581f01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controls that I can add down the road\n",
    "# % of problems that are unlinked prs/linked\n",
    "\n",
    "\n",
    "df_problems_contr_filtered = pd.read_parquet('issue/filtered_problem_data.parquet')\n",
    "df_problems_contr_filtered['departed_involved'] = df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['all_actors'], axis = 1)\n",
    "df_problems_contr_filtered['key_contributor_count'] = df_problems_contr_filtered['important_actors_rolling'].apply(len)\n",
    "df_problems_contr_filtered['total_contributor_count'] = df_problems_contr_filtered['all_actors_period'].apply(len)\n",
    "df_problems_contr_filtered['departed_opener'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_opener'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "df_problems_contr_filtered['departed_author'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_authors'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "\n",
    "df_project_filtered_group = df_problems_contr_filtered.groupby(\n",
    "    ['repo_name', 'time_period', 'treatment_period', 'key_contributor_count', 'total_contributor_count']\n",
    ").agg(\n",
    "    problem_count=('problem_id', 'count'),\n",
    "    ind_collab=('ind_collab_roll', 'mean'),\n",
    "    ind_key_collab=('ind_key_collab_roll', 'mean'),\n",
    "    ind_other_collab=('ind_other_collab_roll', 'mean'),\n",
    "    departed_involved_count=('departed_involved','sum'),\n",
    "    departed_involved=('departed_involved','mean'),\n",
    "    departed_opened_count=('departed_opener','sum'),\n",
    "    departed_opened=('departed_opener','mean'), # conditional on involvement\n",
    "    departed_authored_count=('departed_author','sum'),\n",
    "    departed_authored=('departed_author','mean'), # conditional on involvement\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a21a90-d9ad-4808-b8c2-4e7e8d7d3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributors = df_problems_contr_filtered[['repo_name','time_period','treatment_period','all_actors_period','departed_actor_id']].explode('all_actors_period').sort_values(['repo_name','time_period'])\n",
    "df_project_predeparture_contributors = df_contributors.query('time_period < treatment_period & departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_predeparture_contributors = df_project_predeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_pre_departure'})\n",
    "df_project_nondeparture_contributors = df_contributors.query('departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_nondeparture_contributors = df_project_nondeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_non_departure'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7984659-308b-4ef7-9174-0a1dc5fc27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_problems_contr_filtered_predep = pd.merge(df_problems_contr_filtered, df_project_predeparture_contributors)\n",
    "df_problems_contr_filtered_predep = df_problems_contr_filtered_predep.loc[\n",
    "    df_problems_contr_filtered_predep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_pre_departure']).size, axis=1)\n",
    "]\n",
    "df_problems_contr_filtered_nondep = pd.merge(df_problems_contr_filtered, df_project_nondeparture_contributors)\n",
    "df_problems_contr_filtered_nondep = df_problems_contr_filtered_nondep.loc[\n",
    "    df_problems_contr_filtered_nondep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_non_departure']).size, axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d019b5d-6982-4e02-ba0e-02c073cc413b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_agg_predep = df_problems_contr_filtered_predep.drop_duplicates(['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_predep'})\n",
    "df_agg_nondep = df_problems_contr_filtered_nondep.drop_duplicates(['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_nondep'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85bc29f-fa4e-4fe0-b113-87ecb8b1cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_prs = pd.merge(df_agg_predep, df_agg_nondep, how = 'outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1348b4d5-f100-4839-bef4-1912bccff440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preperiod_recent = df_project_filtered_group.query('time_period < treatment_period').groupby('repo_name').tail(5)\n",
    "preperiod_recent['other_involved_count'] = preperiod_recent['departed_involved_count'] - preperiod_recent['problem_count']\n",
    "preperiod_recent['uniform_weight'] = 1\n",
    "\n",
    "count_dict = {\n",
    "    'ind_collab': 'problem_count',\n",
    "    'ind_key_collab': 'departed_involved_count',\n",
    "    'ind_other_collab': 'other_involved_count',\n",
    "    'departed_involved': 'problem_count',\n",
    "    'departed_involved_count': 'uniform_weight',\n",
    "    'key_contributor_count': 'uniform_weight',\n",
    "    'total_contributor_count': 'uniform_weight',\n",
    "    'problem_count': 'uniform_weight',\n",
    "    'departed_opened': 'departed_opened_count',\n",
    "    'departed_authored': 'departed_authored_count'\n",
    "}\n",
    "\n",
    "for collab_type, count_col in count_dict.items():\n",
    "    avg_collab = WeightedMean(preperiod_recent[collab_type], preperiod_recent[count_col])\n",
    "    base_wm = preperiod_recent.groupby('repo_name').apply(\n",
    "        lambda df: WeightedMean(df[collab_type], df[count_col], zero_weight_return = 0)\n",
    "    )\n",
    "\n",
    "    above_set = set(base_wm[base_wm > avg_collab].index)\n",
    "    df_project_filtered_group[f\"{collab_type}_2bin\"] = df_project_filtered_group['repo_name'].apply(lambda x: int(x in above_set))\n",
    "\n",
    "    # 3-bin: weighted quantiles\n",
    "    q33, q67 = WeightedQuantile(preperiod_recent[collab_type], preperiod_recent[count_col], [0.33, 0.67])\n",
    "\n",
    "    df_project_filtered_group[f\"{collab_type}_3bin\"] = df_project_filtered_group['repo_name'].apply(Assign3Bin)\n",
    "\n",
    "df_project_filtered_group = df_project_filtered_group.merge(df_agg_prs, how = 'left')\n",
    "df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']] = df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']].fillna(0)\n",
    "df_project_filtered_group.to_parquet('issue/project_collaboration.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e9ac8-c3cc-4851-9108-e2e710e27c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
