{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e815d6-c66d-4155-af31-572e47e5992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d3e464-9f3f-4bf5-9f49-1413e70b2c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import warnings\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "from source.lib.JMSLab import autofill\n",
    "from source.lib.helpers import *\n",
    "from ast import literal_eval\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from glob import glob \n",
    "import datetime\n",
    "import itertools\n",
    "import time\n",
    "from multiprocessing import pool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pandarallel.initialize(progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6926de3-7199-4182-83a5-79ca25b75d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir_committers_info = Path('drive/output/scrape/link_committers_profile')\n",
    "indir_data = Path('drive/output/derived/data_export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8928606a-3246-4b18-be6f-d79b69883872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = pd.read_parquet(indir_data / 'df_issue.parquet')\n",
    "df_pr = pd.read_parquet(indir_data / 'df_pr.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4264111b-6d4c-4ad7-990d-98ac1742a7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/output/scrape/link_issue_pull_request/linked_issue/modin-project_modin_linked_issue_to_pull_request.csv\n",
      "drive/output/scrape/link_issue_pull_request/linked_issue/PyMySQL_PyMySQL_linked_issue_to_pull_request.csv\n",
      "drive/output/scrape/link_issue_pull_request/linked_issue/google_grr_linked_issue_to_pull_request.csv\n",
      "drive/output/scrape/link_issue_pull_request/linked_issue/celiao_tmdbsimple_linked_issue_to_pull_request.csv\n",
      "drive/output/scrape/link_issue_pull_request/linked_issue/aaugustin_websockets_linked_issue_to_pull_request.csv\n"
     ]
    }
   ],
   "source": [
    "df_pr_commits = pd.read_parquet(indir_data / 'df_pr_commits.parquet')\n",
    "df_linked_issues = ReadFileList(glob('drive/output/scrape/link_issue_pull_request/linked_issue/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9176e4c-4f59-4f7f-b19f-100445055ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_issue['created_at'] = pd.to_datetime(df_issue['created_at'])\n",
    "df_pr['created_at'] = pd.to_datetime(df_pr['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fdbec8-095b-45b1-ba28-7e10ea751759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 100\n",
    "commit_cols = ['commits','commit additions','commit deletions','commit changes total','commit files changed count']\n",
    "author_thresh = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795361e4-3eb3-4bb3-9742-96edb8748052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanCommittersInfo(indir_committers_info):\n",
    "    # TODO: edit file so it can handle pushes\n",
    "    df_committers_info = pd.read_csv(indir_committers_info / 'committers_info_pr.csv', index_col = 0).dropna()\n",
    "    df_committers_info['committer_info'] = df_committers_info['committer_info'].apply(literal_eval)\n",
    "    # TODO: handle cleaning so that it can handle the other cases\n",
    "    df_committers_info = df_committers_info[df_committers_info['committer_info'].apply(lambda x: len(x)==4)]\n",
    "    df_committers_info['actor_name'] = df_committers_info['committer_info'].apply(lambda x: x[0])\n",
    "    df_committers_info['actor_id'] = df_committers_info['committer_info'].apply(lambda x: x[1])\n",
    "\n",
    "    committers_match = df_committers_info[['name','email','user_type','actor_name','actor_id']].drop_duplicates()\n",
    "    committers_match.rename({'actor_id':'commit_author_id'}, axis = 1, inplace = True)\n",
    "\n",
    "    return committers_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d626d84-9fa2-49a9-9b08-d132e76d4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinkPRCommits(df_pr_selected, df_pr_commits_selected, committers_match, commit_cols):\n",
    "\n",
    "    # TODO: what % of commits were dropped because nobody could be found\n",
    "    matched_commits = pd.merge(df_pr_commits_selected, committers_match,\n",
    "                               how = 'inner', left_on = ['commit author name','commit author email'],\n",
    "                               right_on = ['name','email'])\n",
    "    matched_commits = matched_commits.assign(commits=1)\n",
    "    \n",
    "    matched_commits_total = matched_commits.groupby(['repo_name','pr_number'])\\\n",
    "        [commit_cols].sum()\n",
    "    matched_commits_total.columns = [col + ' total' for col in commit_cols]\n",
    "    matched_commits_share = pd.merge(\n",
    "        matched_commits,\n",
    "        matched_commits_total.reset_index(), on = ['repo_name','pr_number'])\n",
    "    \n",
    "    for col in commit_cols:\n",
    "        matched_commits_share[f\"{col} share\"] = matched_commits_share[col]/matched_commits_share[f\"{col} total\"]\n",
    "\n",
    "    final_agg_cols = commit_cols + [f\"{col} share\" for col in commit_cols]\n",
    "    commit_stats = matched_commits_share\\\n",
    "        .assign(commits=1)\\\n",
    "        .groupby(['repo_name','pr_number','commit_author_id'])\\\n",
    "        [final_agg_cols].sum().reset_index()\n",
    "    \n",
    "    merged_commits = df_pr_selected.query('pr_action == \"closed\" & ~pr_merged_by_id.isna()')\n",
    "    # TODO: what % of commits had truncated information bc 250 max - also, is that push or PR? \n",
    "    # TODO: what % of commits could we not get information for\n",
    "    df_commit_stats = pd.merge(merged_commits, commit_stats, on = ['repo_name','pr_number'])\n",
    "\n",
    "    return df_commit_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a1ff36-ad76-45a1-944a-f429abcf53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinkIssuePR(df_issue_selected, df_linked_issues):\n",
    "    df_linked_issues = df_linked_issues.query('linked_pull_request != \"list index out of range\"')\n",
    "    df_linked_issues['linked_pr_number'] = df_linked_issues['linked_pull_request'].apply(lambda x: x.split(\"/\")[-1])\n",
    "    df_issue_pr = df_linked_issues[['repo_name','issue_number', 'linked_pr_number']].drop_duplicates()\n",
    "\n",
    "    df_issue_selected = pd.merge(df_issue_selected, df_issue_pr, how = 'left', on = ['repo_name','issue_number'])\n",
    "\n",
    "    return df_issue_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed90c74-26c2-45aa-9a09-43d163a14797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterDuplicateIssues(df, query):\n",
    "    df_sel = df.query(query)\\\n",
    "        .sort_values(['repo_name','issue_number','created_at'])\\\n",
    "        [['repo_name','actor_id', 'issue_user_id','issue_number', \n",
    "          'issue_comment_id', 'created_at', 'linked_pr_number']]\\\n",
    "        .dropna(subset = ['issue_number'])\\\n",
    "        .dropna(axis=1, how='all')\\\n",
    "        .drop_duplicates()\n",
    "\n",
    "    return df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "650b2226-9867-401d-a0fc-6749ab9f3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImputeTimePeriod(df, time_period_months):\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['year'] = df['created_at'].apply(lambda x: x.year)\n",
    "    \n",
    "    df['period'] = df['created_at'].apply(lambda x: int(x.month>6))\n",
    "    df['time_period'] = df['created_at'].apply(lambda x: datetime.date(x.year, int(np.floor(x.month/time_period_months)+1), 1))\n",
    "    df['time_period'] = pd.to_datetime(df['time_period'])\n",
    "    \n",
    "    df_period_index = df[['year','period']].drop_duplicates()\\\n",
    "        .sort_values(['year','period'], ascending = True)\\\n",
    "        .reset_index(drop = True)\n",
    "    df_period_index['index'] = df_period_index.index\n",
    "    df = pd.merge(df, df_period_index).drop(['year','period'], axis = 1)\\\n",
    "        .rename({'index': 'time_period_index'}, axis = 1)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3053eb2a-fa50-49db-818d-f25a802920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignPRAuthorship(df_pr_commit_stats, author_thresh, commit_cols):\n",
    "    commit_cols_share = [f\"{col} share\" for col in commit_cols]\n",
    "    commit_author_bool = df_pr_commit_stats.apply(lambda x: any([x[col]>author_thresh for col in commit_cols_share]), axis = 1)\n",
    "    df_pr_commit_author_stats = df_pr_commit_stats[commit_author_bool]\n",
    "    return df_pr_commit_author_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0956b327-8045-4309-85e8-d517307f0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateColumnPercentile(df, repo, window, col, pct): \n",
    "    df_repo = df[df['repo_name'] == repo]\n",
    "    df_pct = df_repo.set_index('time_period')\\\n",
    "        [col].resample(\"1d\")\\\n",
    "        .quantile(pct)\\\n",
    "        .rolling(window = window, min_periods = 1)\\\n",
    "        .mean()\\\n",
    "        .rename(f'{col}_{int(pct*100)}th_pct')\\\n",
    "        .reset_index()\n",
    "    df_repo = pd.merge(df_repo, df_pct, on = ['time_period'])\n",
    "\n",
    "    return df_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2480023a-37bb-4ba6-9b88-5eea44b3cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateColumnPercentileDF(df, window, col, pct, general_pct): \n",
    "    repo_list = df['repo_name'].unique().tolist()\n",
    "    \n",
    "    with ThreadPoolExecutor(8) as pool:\n",
    "        df = pd.concat(pool.map(CalculateColumnPercentile, itertools.repeat(df), repo_list, itertools.repeat(window), itertools.repeat(col), itertools.repeat(pct)))\n",
    "\n",
    "    df_all_pct = df.set_index('time_period')\\\n",
    "        [col].resample(\"1d\")\\\n",
    "        .quantile(general_pct)\\\n",
    "        .rolling(window = window, min_periods = 1)\\\n",
    "        .mean()\\\n",
    "        .rename(f'general_{col}_{int(general_pct*100)}th_pct')\\\n",
    "        .reset_index()\n",
    "    df = pd.merge(df, df_all_pct, on = ['time_period'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5feda96e-2f7d-435b-8ffa-cafadb224eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_repos = df_issue[['repo_name']].drop_duplicates()['repo_name'].tolist()#.sample(sample_num, random_state = 123)['repo_name'].tolist()\n",
    "\n",
    "df_issue_selected = df_issue[(df_issue['repo_name'].isin(selected_repos)) & (df_issue['created_at']>='2015-01-01')]\n",
    "df_pr_selected = df_pr[(df_pr['repo_name'].isin(selected_repos))  & (df_pr['created_at']>='2015-01-01')]\n",
    "df_pr_commits_selected = df_pr_commits[(df_pr_commits['repo_name'].isin(selected_repos))]\n",
    "df_linked_issues = df_linked_issues[(df_linked_issues['repo_name'].isin(selected_repos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6efdcc85-7183-42a9-a017-763d8815d815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options_list = []\n",
    "for major_pct_options in [0.75, 0.9, 0.95]:\n",
    "    for general_pct_options in [0.25, 0.5, 0.75]:\n",
    "        for time_period_months_options in [2, 3, 6, 12]:\n",
    "            options_list.append([major_pct_options, general_pct_options, time_period_months_options])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ef0035-288b-48b5-b1d0-f414b094759a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "committers_match = CleanCommittersInfo(indir_committers_info)\n",
    "df_pr_commit_stats = LinkPRCommits(df_pr_selected, df_pr_commits_selected, committers_match, commit_cols)\n",
    "df_issue_selected = LinkIssuePR(df_issue_selected, df_linked_issues)\n",
    "issue_comments = FilterDuplicateIssues(df_issue_selected, 'type == \"IssueCommentEvent\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9db84354-903b-41bc-9584-7361491f7191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetMajorContributorPostpercentile(ts_data, rolling_window, major_col, major_pct, general_pct):\n",
    "    ts_data = ts_data.reset_index()\\\n",
    "        .sort_values(['repo_name','time_period_index','actor_id'])\n",
    "\n",
    "    \n",
    "    repo_pct_col = f'{major_col}_{int(major_pct*100)}th_pct'\n",
    "    general_pct_col = f'general_{major_col}_{int(general_pct*100)}th_pct'\n",
    "    major_cols = ['time_period','time_period_index', 'repo_name','actor_id', major_col,\n",
    "                  repo_pct_col, general_pct_col]\n",
    "    \n",
    "    ts_data_pct = CalculateColumnPercentileDF(ts_data, '1828D', major_col, major_pct, general_pct)\n",
    "    major_contributor_data = ts_data_pct[major_cols].query(f'{major_col}>{repo_pct_col} & {major_col}>{general_pct_col}')\n",
    "\n",
    "    return major_contributor_data\n",
    "\n",
    "def GroupedFill(df, group, fill_cols):\n",
    "    df[fill_cols] = major_contributors_data.groupby(group)[fill_cols].ffill()\n",
    "    df[fill_cols] = major_contributors_data.groupby(group)[fill_cols].bfill()\n",
    "\n",
    "    return df\n",
    "\n",
    "def GenerateBalancedContributorsPanel(ic_major_contributor_data, pr_major_contributor_data):\n",
    "    major_contributors = pd.concat([ic_major_contributor_data[['repo_name','actor_id']].drop_duplicates(),\n",
    "                                    pr_major_contributor_data[['repo_name','actor_id']].drop_duplicates()]).drop_duplicates()\n",
    "    time_periods = sorted(ic_major_contributor_data['time_period'].unique().tolist())\n",
    "    major_contributors['time_period'] = [time_periods for i in range(major_contributors.shape[0])]\n",
    "    major_contributors_data = major_contributors.explode('time_period').reset_index(drop = True)\n",
    "    major_contributors_data = pd.merge(major_contributors_data, ic_major_contributor_data, how = 'left')\n",
    "    major_contributors_data = pd.merge(major_contributors_data, pr_major_contributor_data, how = 'left')\n",
    "\n",
    "    return major_contributors_data\n",
    "\n",
    "def RemovePeriodsPriorToJoining(major_contributors_data):\n",
    "    contributor_earliest = major_contributors_data.dropna().sort_values('time_period')\\\n",
    "        [['repo_name','actor_id','time_period']]\\\n",
    "        .drop_duplicates(['repo_name','actor_id'])\\\n",
    "        .rename({'time_period':'earliest_appearance'}, axis = 1)\n",
    "    major_contributors_data = pd.merge(major_contributors_data, contributor_earliest, how = 'inner', on = ['repo_name','actor_id'])\n",
    "    major_contributors_data = major_contributors_data.query('time_period>=earliest_appearance')\n",
    "\n",
    "    return major_contributors_data\n",
    "\n",
    "\n",
    "def OutputMajorContributors(committers_match, df_pr_commit_stats, df_issue_selected, issue_comments, options):\n",
    "    major_pct = options[0]\n",
    "    general_pct = options[1]\n",
    "    time_period = options[2]\n",
    "\n",
    "    df_pr_commit_stats = ImputeTimePeriod(df_pr_commit_stats, time_period)\n",
    "    df_pr_commit_author_stats = AssignPRAuthorship(df_pr_commit_stats, author_thresh, commit_cols)\n",
    "    ts_pr_authorship = df_pr_commit_author_stats.assign(pr = 1)\\\n",
    "        .groupby(['time_period', 'time_period_index', 'repo_name','actor_id'])\\\n",
    "        [['pr'] + commit_cols + [f\"{col} share\" for col in commit_cols]].sum()\n",
    "    \n",
    "    major_pr_col = 'pr'\n",
    "    rolling_window = '1828D'\n",
    "    pr_major_contributor_data = GetMajorContributorPostpercentile(ts_pr_authorship, rolling_window, major_pr_col, major_pct, general_pct)\n",
    "    print(\"percentile for PRs obtained\")\n",
    "    issue_comments = ImputeTimePeriod(issue_comments, time_period)\n",
    "    ts_issue_comments = issue_comments.assign(issue_comments=1)\\\n",
    "        .groupby(['time_period','time_period_index', 'repo_name','actor_id'])\\\n",
    "        ['issue_comments'].sum()\n",
    "\n",
    "    major_ic_col = 'issue_comments'\n",
    "    ic_major_contributor_data = GetMajorContributorPostpercentile(ts_issue_comments, rolling_window, major_ic_col, major_pct, general_pct)\n",
    "    print(\"percentile for issues obtained\")\n",
    "    major_contributors_data = GenerateBalancedContributorsPanel(ic_major_contributor_data, pr_major_contributor_data)\n",
    "\n",
    "    major_contributors_data = RemovePeriodsPriorToJoining(major_contributors_data)\n",
    "\n",
    "    pct_cols = [repo_pct_pr_col, general_pct_pr_col, repo_pct_ic_col, general_pct_ic_col]\n",
    "    major_cols = [major_pr_col, major_ic_col]\n",
    "\n",
    "    major_contributors_data = GroupedFill(major_contributors_data, ['repo_name','time_period'], pct_cols)\n",
    "    major_contributors_data = GroupedFill(major_contributors_data, ['repo_name','time_period'], ['time_period_index'])\n",
    "    major_contributors_data[major_cols] = major_contributors_data[major_cols].fillna(0)\n",
    "\n",
    "    print(f\"Major PCT: {major_pct}, General PCT: {general_pct}, Time Period: {time_period} months\")\n",
    "    print(major_contributors_data[['repo_name','actor_id']].drop_duplicates().shape)\n",
    "    major_contributors_data.to_csv(f'issue/major_contributors_major{major_pct}_general{general_pct}_months{time_period}.csv')\n",
    "    print(\"major contributors exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ceba6c-588c-40a8-8837-abfbb15a260b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e145dd-7288-484e-bbfa-e0dbe99aad1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Series_1_0x100xe60xc80x880x870x7f0x00x0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/site-packages/numexpr/necompiler.py:760\u001b[0m, in \u001b[0;36mgetArguments\u001b[0;34m(names, local_dict, global_dict, _frame_depth)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/collections/__init__.py:1015\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__missing__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/collections/__init__.py:1007\u001b[0m, in \u001b[0;36mChainMap.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Series_1_0x100xe60xc80x880x870x7f0x00x0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m options \u001b[38;5;129;01min\u001b[39;00m options_list:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mOutputMajorContributors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommitters_match\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_pr_commit_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_issue_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43missue_comments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(major_contributors_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[26], line 57\u001b[0m, in \u001b[0;36mOutputMajorContributors\u001b[0;34m(committers_match, df_pr_commit_stats, df_issue_selected, issue_comments, options)\u001b[0m\n\u001b[1;32m     55\u001b[0m major_pr_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m rolling_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1828D\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m pr_major_contributor_data \u001b[38;5;241m=\u001b[39m \u001b[43mGetMajorContributorPostpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_pr_authorship\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrolling_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor_pr_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor_pct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneral_pct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercentile for PRs obtained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m issue_comments \u001b[38;5;241m=\u001b[39m ImputeTimePeriod(issue_comments, time_period)\n",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m, in \u001b[0;36mGetMajorContributorPostpercentile\u001b[0;34m(ts_data, rolling_window, major_col, major_pct, general_pct)\u001b[0m\n\u001b[1;32m      7\u001b[0m general_pct_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmajor_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(general_pct\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth_pct\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m major_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, major_col,\n\u001b[1;32m      9\u001b[0m               repo_pct_col, general_pct_col]\n\u001b[0;32m---> 11\u001b[0m ts_data_pct \u001b[38;5;241m=\u001b[39m \u001b[43mCalculateColumnPercentileDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1828D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor_pct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneral_pct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m major_contributor_data \u001b[38;5;241m=\u001b[39m ts_data_pct[major_cols]\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmajor_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_pct_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m & \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmajor_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneral_pct_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m major_contributor_data\n",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m, in \u001b[0;36mCalculateColumnPercentileDF\u001b[0;34m(df, window, col, pct, general_pct)\u001b[0m\n\u001b[1;32m      2\u001b[0m repo_list \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(\u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCalculateColumnPercentile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpct\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df_all_pct \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m      8\u001b[0m     [col]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mquantile(general_pct)\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(general_pct\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth_pct\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, df_all_pct, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:504\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mCalculateColumnPercentile\u001b[0;34m(df, repo, window, col, pct)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCalculateColumnPercentile\u001b[39m(df, repo, window, col, pct): \n\u001b[0;32m----> 2\u001b[0m     df_repo \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrepo_name == \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df_pct \u001b[38;5;241m=\u001b[39m df_repo\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m      4\u001b[0m         [col]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39mquantile(pct)\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(pct\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth_pct\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     10\u001b[0m     df_repo \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_repo, df_pct, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_period\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4823\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4821\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4822\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4823\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4825\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4826\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[res]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4949\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4946\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   4947\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m, ())) \u001b[38;5;241m+\u001b[39m resolvers\n\u001b[0;32m-> 4949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/computation/eval.py:357\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    355\u001b[0m eng \u001b[38;5;241m=\u001b[39m ENGINES[engine]\n\u001b[1;32m    356\u001b[0m eng_inst \u001b[38;5;241m=\u001b[39m eng(parsed_expr)\n\u001b[0;32m--> 357\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43meng_inst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed_expr\u001b[38;5;241m.\u001b[39massigner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_line:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/computation/engines.py:81\u001b[0m, in \u001b[0;36mAbstractEngine.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligned_axes \u001b[38;5;241m=\u001b[39m align_terms(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr\u001b[38;5;241m.\u001b[39mterms)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# make sure no names in resolvers and locals/globals clash\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reconstruct_object(\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_type, res, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maligned_axes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr\u001b[38;5;241m.\u001b[39mterms\u001b[38;5;241m.\u001b[39mreturn_type\n\u001b[1;32m     84\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/computation/engines.py:121\u001b[0m, in \u001b[0;36mNumExprEngine._evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m scope \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mfull_scope\n\u001b[1;32m    120\u001b[0m _check_ne_builtin_clash(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/site-packages/numexpr/necompiler.py:973\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, sanitize, _frame_depth, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m e \u001b[38;5;241m=\u001b[39m validate(ex, local_dict\u001b[38;5;241m=\u001b[39mlocal_dict, global_dict\u001b[38;5;241m=\u001b[39mglobal_dict, \n\u001b[1;32m    970\u001b[0m              out\u001b[38;5;241m=\u001b[39mout, order\u001b[38;5;241m=\u001b[39morder, casting\u001b[38;5;241m=\u001b[39mcasting, \n\u001b[1;32m    971\u001b[0m              _frame_depth\u001b[38;5;241m=\u001b[39m_frame_depth, sanitize\u001b[38;5;241m=\u001b[39msanitize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_frame_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frame_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/site-packages/numexpr/necompiler.py:1001\u001b[0m, in \u001b[0;36mre_evaluate\u001b[0;34m(local_dict, _frame_depth)\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA previous evaluate() execution was not found, please call `validate` or `evaluate` once before `re_evaluate`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1000\u001b[0m argnames \u001b[38;5;241m=\u001b[39m _numexpr_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnames\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1001\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mgetArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43margnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_frame_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frame_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _numexpr_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m evaluate_lock:\n",
      "File \u001b[0;32m~/.conda/envs/oss_hierarchy/lib/python3.12/site-packages/numexpr/necompiler.py:762\u001b[0m, in \u001b[0;36mgetArguments\u001b[0;34m(names, local_dict, global_dict, _frame_depth)\u001b[0m\n\u001b[1;32m    760\u001b[0m             a \u001b[38;5;241m=\u001b[39m local_dict[name]\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m             a \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    763\u001b[0m         arguments\u001b[38;5;241m.\u001b[39mappend(numpy\u001b[38;5;241m.\u001b[39masarray(a))\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# If we generated local_dict via an explicit reference to f_locals,\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# clear the dict to prevent creating extra ref counts in the caller's scope\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pydata/numexpr/issues/310\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Series_1_0x100xe60xc80x880x870x7f0x00x0'"
     ]
    }
   ],
   "source": [
    "for options in options_list:\n",
    "    OutputMajorContributors(committers_match, df_pr_commit_stats, df_issue_selected, issue_comments, options)\n",
    "    print(major_contributors_data[['repo_name','actor_id']].drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec45686-9b5a-4d26-acaf-116200db8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(4) as pool:\n",
    "    pool.map(OutputMajorContributors, itertools.repeat(committers_match), itertools.repeat(df_pr_commit_stats), itertools.repeat(df_issue_selected), \n",
    "             itertools.repeat(issue_comments), options_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b07df3d3-e130-414a-832b-00ed3f911919",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'major_contributors_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: What % was dropped at each stage\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmajor_contributors_data\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#major_contributors_data.to_csv(f'major_contributors_{sample_num}.csv')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'major_contributors_data' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: What % was dropped at each stage\n",
    "#major_contributors_data[['repo_name','actor_id']].drop_duplicates().shape\n",
    "#major_contributors_data.to_csv(f'major_contributors_{sample_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691c45e-82b7-415d-be75-c7ff428dcc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: autofill about ignoring reopenings\n",
    "np.mean(df_issue['issue_action']=='reopened')\n",
    "options = options_list[0]\n",
    "major_pct = options[0]\n",
    "general_pct = options[1]\n",
    "time_period = options[2]\n",
    "\n",
    "df_pr_commit_stats = ImputeTimePeriod(df_pr_commit_stats, time_period)\n",
    "df_pr_commit_author_stats = AssignPRAuthorship(df_pr_commit_stats, author_thresh, commit_cols)\n",
    "ts_pr_authorship = df_pr_commit_author_stats.assign(pr = 1)\\\n",
    "    .groupby(['time_period', 'time_period_index', 'repo_name','actor_id'])\\\n",
    "    [['pr'] + commit_cols + [f\"{col} share\" for col in commit_cols]].sum()\n",
    "\n",
    "major_pr_col = 'pr'\n",
    "rolling_window = '1828D'\n",
    "pr_major_contributor_data = GetMajorContributorPostpercentile(ts_pr_authorship, rolling_window, major_pr_col, major_pct, general_pct)\n",
    "print(\"percentile for PRs obtained\")\n",
    "issue_comments = ImputeTimePeriod(issue_comments, time_period)\n",
    "ts_issue_comments = issue_comments.assign(issue_comments=1)\\\n",
    "    .groupby(['time_period','time_period_index', 'repo_name','actor_id'])\\\n",
    "    ['issue_comments'].sum()\n",
    "\n",
    "major_ic_col = 'issue_comments'\n",
    "ic_major_contributor_data = GetMajorContributorPostpercentile(ts_issue_comments, rolling_window, major_ic_col, major_pct, general_pct)\n",
    "print(\"percentile for issues obtained\")\n",
    "major_contributors_data = GenerateBalancedContributorsPanel(ic_major_contributor_data, pr_major_contributor_data)\n",
    "\n",
    "major_contributors_data = RemovePeriodsPriorToJoining(major_contributors_data)\n",
    "\n",
    "pct_cols = [repo_pct_pr_col, general_pct_pr_col, repo_pct_ic_col, general_pct_ic_col]\n",
    "major_cols = [major_pr_col, major_ic_col]\n",
    "\n",
    "major_contributors_data = GroupedFill(major_contributors_data, ['repo_name','time_period'], pct_cols)\n",
    "major_contributors_data = GroupedFill(major_contributors_data, ['repo_name','time_period'], ['time_period_index'])\n",
    "major_contributors_data[major_cols] = major_contributors_data[major_cols].fillna(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_hierarchy",
   "language": "python",
   "name": "oss_hierarchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
