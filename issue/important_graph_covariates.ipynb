{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e61c0ba-1d93-42d4-b7cc-00514cffdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b4b32b0-4f94-4e30-91fb-cb459affb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb95420-0dc0-4e09-9515-a7519e2526fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"issue/graph_metrics.json\", \"r\") as f:\n",
    "    graph_metrics = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65f25fb-6a3e-4a95-ac5c-7b7cfd9e14c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "\n",
    "for repo, time_dict in graph_metrics.items():\n",
    "    for t_str, project_time in time_dict.items():\n",
    "        year = int(t_str[:4])\n",
    "        month = int(t_str[4:6])\n",
    "        time_period = datetime(year, month, 1)\n",
    "        \n",
    "        # Extract project-level metrics\n",
    "        overall = project_time.get('repo_overall', {})\n",
    "        total_important = overall.get('total_important', None)\n",
    "        total_nodes = overall.get('total_nodes', None)\n",
    "        cluster_averages = overall.get('cluster_averages', {})\n",
    "        mean_overlap = cluster_averages.get('mean_overlap', None)\n",
    "        avg_clusters_per_node = cluster_averages.get('avg_clusters_per_node', None)\n",
    "        pct_nodes_one_cluster = cluster_averages.get('pct_nodes_one_cluster', None)\n",
    "        \n",
    "        # important contributors\n",
    "        important_contributor_keys = [k for k in project_time.keys() if k != 'repo_overall']\n",
    "        \n",
    "        # Compute HHI values for three metrics across actors in this project_time.\n",
    "        total_norm = sum(project_time[actor].get('normalized_degree', 0) for actor in important_contributor_keys)\n",
    "        total_ind_cov = sum(project_time[actor].get('individual_coverage', 0) for actor in important_contributor_keys)\n",
    "        total_ind_cov_cluster = sum(project_time[actor].get('individual_coverage_cluster', 0) for actor in important_contributor_keys)\n",
    "        \n",
    "        hhi_norm = sum((project_time[actor].get('normalized_degree', 0)/total_norm)**2 for actor in important_contributor_keys) if total_norm > 0 else None\n",
    "        hhi_ind_cov = sum((project_time[actor].get('individual_coverage', 0)/total_ind_cov)**2 for actor in important_contributor_keys) if total_ind_cov > 0 else None\n",
    "        hhi_ind_cov_cluster = sum((project_time[actor].get('individual_coverage_cluster', 0)/total_ind_cov_cluster)**2 for actor in important_contributor_keys) if total_ind_cov_cluster > 0 else None\n",
    "        \n",
    "        for actor in important_contributor_keys:\n",
    "            actor_data = project_time[actor]\n",
    "            row = {\n",
    "                'repo_name': repo,\n",
    "                'time_period': time_period,\n",
    "                'actor_id': actor,\n",
    "                'total_important': total_important,\n",
    "                'total_nodes': total_nodes,\n",
    "                'mean_cluster_overlap': mean_overlap,\n",
    "                'avg_clusters_per_node': avg_clusters_per_node,\n",
    "                'pct_nodes_one_cluster': pct_nodes_one_cluster,\n",
    "                'HHI_normalized_degree': hhi_norm,\n",
    "                'HHI_individual_coverage': hhi_ind_cov,\n",
    "                'HHI_individual_coverage_cluster': hhi_ind_cov_cluster,\n",
    "                'normalized_degree': actor_data.get('normalized_degree', None),\n",
    "                'individual_node_coverage': actor_data.get('individual_coverage', None),\n",
    "                'individual_coverage_cluster': actor_data.get('individual_coverage_cluster', None),\n",
    "                'overall_overlap': actor_data.get('overall_overlap', None),\n",
    "                'weighted_overall_overlap': actor_data.get('weighted_overall_overlap', None),\n",
    "                'imp_to_other_avg_edge_weight': actor_data.get('avg_edge_weight', None)\n",
    "            }\n",
    "            # Add actor-level percentiles\n",
    "            perc = actor_data.get('percentiles', {})\n",
    "            row['imp_to_other_perc_10'] = perc.get('10', None)\n",
    "            row['imp_to_other_perc_25'] = perc.get('25', None)\n",
    "            row['imp_to_other_perc_50'] = perc.get('50', None)\n",
    "            row['imp_to_other_perc_75'] = perc.get('75', None)\n",
    "            row['imp_to_other_perc_90'] = perc.get('90', None)\n",
    "            \n",
    "            # Add important-to-important communication metrics\n",
    "            imp_comm = actor_data.get('imp_to_imp_comm', {})\n",
    "            row['imp_to_imp_avg_edge_weight'] = imp_comm.get('avg_edge_weight', None)\n",
    "            imp_comm_perc = imp_comm.get('percentiles', {})\n",
    "            row['imp_to_imp_perc_10'] = imp_comm_perc.get('10', None)\n",
    "            row['imp_to_imp_perc_25'] = imp_comm_perc.get('25', None)\n",
    "            row['imp_to_imp_perc_50'] = imp_comm_perc.get('50', None)\n",
    "            row['imp_to_imp_perc_75'] = imp_comm_perc.get('75', None)\n",
    "            row['imp_to_imp_perc_90'] = imp_comm_perc.get('90', None)\n",
    "            \n",
    "            rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['time_period'] = pd.to_datetime(df['time_period'])\n",
    "df['prop_important'] = df['total_important']/df['total_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4052a4-956d-47e8-9ffc-cb86d96e87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leave_one_out(df):\n",
    "    # Compute the per-row product\n",
    "    df = df.copy()\n",
    "    df['weighted'] = df['normalized_degree'] * df['overall_overlap']\n",
    "    # Compute group sums using transform (which returns a Series aligned with df)\n",
    "    sum_w  = df.groupby(['repo_name','time_period'])['normalized_degree'].transform('sum')\n",
    "    sum_wx = df.groupby(['repo_name','time_period'])['weighted'].transform('sum')\n",
    "    # Compute leave-one-out weighted mean for each row:\n",
    "    # (group sum of weighted - row weighted) divided by (group sum of weights - row weight)\n",
    "    df['leave_one_out_mean_cluster_overlap'] = (sum_wx - df['weighted']) / (sum_w - df['normalized_degree'])\n",
    "    return df\n",
    "\n",
    "df = compute_leave_one_out(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a503a47-7b16-4a22-95c8-8a82979f7771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('issue/graph_important.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_hierarchy",
   "language": "python",
   "name": "oss_hierarchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
