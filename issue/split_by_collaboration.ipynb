{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7353ca-7a0a-49bf-b138-d7ea242d1972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252286ad-d984-4fb0-8e31-b0da5354bee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from source.lib.helpers import *\n",
    "from pandarallel import pandarallel\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac22f5f-f1a9-425a-b0af-6c29cf722dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightedQuantile(values, weights, quantiles):\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    sorter = np.argsort(values)\n",
    "    values = values[sorter]\n",
    "    weights = weights[sorter]\n",
    "    cumulative_weight = np.cumsum(weights)\n",
    "    total_weight = cumulative_weight[-1]\n",
    "    return np.interp(np.array(quantiles) * total_weight, cumulative_weight, values)\n",
    "\n",
    "def Assign3Bin(repo):\n",
    "    val = base_wm[repo]\n",
    "    if val <= q33:\n",
    "        return 0\n",
    "    elif val <= q67:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def ConvertLogKeysToInt(log_dict):\n",
    "    return {int(float(key)): value for key, value in log_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97954a0d-146a-419d-9ade-65fcd5762c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_problems_contr_filtered = pd.read_parquet('issue/filtered_problem_data.parquet')\n",
    "#df_problems_contr_filtered = df_problems_contr_filtered.query('time_period>=\"2015-01-01\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0499952-7886-4301-a075-0b4156f4853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectLevelStats(df_problems_contr_filtered):\n",
    "    # controls that I can add down the road\n",
    "    # % of problems that are unlinked prs/linked\n",
    "    df_problems_contr_filtered['departed_involved'] = df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['all_actors'], axis = 1)\n",
    "    df_problems_contr_filtered['key_contributor_count'] = df_problems_contr_filtered['important_actors_rolling'].apply(len)\n",
    "    df_problems_contr_filtered['total_contributor_count'] = df_problems_contr_filtered['all_actors_period'].apply(len)\n",
    "    df_problems_contr_filtered['departed_opener'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_opener'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "    df_problems_contr_filtered['departed_author'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_authors'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "    \n",
    "    df_project_filtered_group = df_problems_contr_filtered.groupby(\n",
    "        ['repo_name', 'time_period', 'treatment_period', 'key_contributor_count', 'total_contributor_count']\n",
    "    ).agg(\n",
    "        problem_count=('problem_id', 'count'),\n",
    "        ind_collab=('ind_collab_roll', 'mean'),\n",
    "        ind_key_collab=('ind_key_collab_roll', 'mean'),\n",
    "        ind_other_collab=('ind_other_collab_roll', 'mean'),\n",
    "        departed_involved_count=('departed_involved','sum'),\n",
    "        departed_involved=('departed_involved','mean'),\n",
    "        departed_opened_count=('departed_opener','sum'),\n",
    "        departed_opened=('departed_opener','mean'), # conditional on involvement\n",
    "        departed_authored_count=('departed_author','sum'),\n",
    "        departed_authored=('departed_author','mean'), # conditional on involvement\n",
    "    ).reset_index()\n",
    "    return df_project_filtered_group\n",
    "\n",
    "df_project_filtered_group = ProjectLevelStats(df_problems_contr_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac211772-3ee9-4ef4-bea7-0884b6f948b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ProjectSummaryStats(df_problems_contr_filtered):\n",
    "    df_problems_contr_filtered['contr_count'] = df_problems_contr_filtered['all_actors_period'].apply(lambda x: len(np.fromstring(x)))\n",
    "    df_problems_contr_filtered['problem_count'] = 1\n",
    "    df_problems_contr_filtered['unlinked_issue_count'] = df_problems_contr_filtered['type'].apply(lambda x: x == \"unlinked issue\")\n",
    "    df_problems_contr_filtered['unlinked_pr_count'] = df_problems_contr_filtered['type'].apply(lambda x: x == \"unlinked pr\")\n",
    "    df_problems_contr_filtered['linked_issue_pr_count'] = df_problems_contr_filtered['type'].apply(lambda x: x == \"linked\")\n",
    "    \n",
    "    df_problems_repo_period = (\n",
    "        df_problems_contr_filtered\n",
    "          .groupby(['repo_name', 'time_period'], as_index=False)\n",
    "          .agg(\n",
    "              contr_count=('contr_count','first'),\n",
    "              problem_count=('problem_count','sum'),\n",
    "              unlinked_issue_count=('unlinked_issue_count','sum'),\n",
    "              unlinked_pr_count=('unlinked_pr_count','sum'),\n",
    "              linked_issue_pr_count=('linked_issue_pr_count','sum'),\n",
    "              discussion_count=('total_prob_contr', 'sum'),\n",
    "              contributor_count_problem=('problem_contr_count', 'sum'),\n",
    "          )\n",
    "    )\n",
    "    df_problems_repo_period['discussion_count_per_problem'] = df_problems_repo_period['discussion_count']/df_problems_repo_period['problem_count']\n",
    "    df_problems_repo_period['contributor_count_problem_per_problem'] = df_problems_repo_period['contributor_count_problem']/df_problems_repo_period['problem_count']\n",
    "\n",
    "    # 1) Compute mean + exact percentiles for your metrics\n",
    "    metrics = df_problems_repo_period[[\n",
    "        'contr_count',\n",
    "        'problem_count',\n",
    "        'unlinked_issue_count',\n",
    "        'unlinked_pr_count',\n",
    "        'linked_issue_pr_count',\n",
    "        'discussion_count_per_problem',\n",
    "        'contributor_count_problem_per_problem'\n",
    "    ]]\n",
    "    means = metrics.mean()\n",
    "    qs = metrics.quantile([0.1, 0.25, 0.5, 0.75, 0.9], interpolation='nearest')\n",
    "    metrics_summary = pd.DataFrame({\n",
    "        'Mean': means,\n",
    "        '10th': qs.loc[0.1],\n",
    "        '25th': qs.loc[0.25],\n",
    "        '50th': qs.loc[0.5],\n",
    "        '75th': qs.loc[0.75],\n",
    "        '90th': qs.loc[0.9],\n",
    "    })\n",
    "    \n",
    "    # 2) Compute time periods per project summary\n",
    "    periods = df_problems_repo_period.groupby('repo_name')['time_period'].count()\n",
    "    p_qs = periods.quantile([0.1, 0.25, 0.5, 0.75, 0.9], interpolation='nearest')\n",
    "    periods_summary = pd.DataFrame({\n",
    "        'Mean': periods.mean(),\n",
    "        '10th': p_qs.loc[0.1],\n",
    "        '25th': p_qs.loc[0.25],\n",
    "        '50th': p_qs.loc[0.5],\n",
    "        '75th': p_qs.loc[0.75],\n",
    "        '90th': p_qs.loc[0.9],\n",
    "    }, index=['Time periods per project'])\n",
    "    \n",
    "    # 3) Combine summaries and set labels\n",
    "    summary = pd.concat([metrics_summary, periods_summary])\n",
    "    summary.index = [\n",
    "        'Contributors',\n",
    "        'Problems',\n",
    "        'Unlinked issues',\n",
    "        'Unlinked pull requests',\n",
    "        'Linked issue–pull request pairs',\n",
    "        'Discussions per problem',\n",
    "        'Contributors per problem',\n",
    "        'Time periods per project'\n",
    "    ]\n",
    "    \n",
    "    # 4) Define formatter: drop .00 for integers, else two decimals\n",
    "    def format_value(x):\n",
    "        if pd.isna(x):\n",
    "            return ''\n",
    "        if float(x).is_integer():\n",
    "            return f\"{int(x)}\"\n",
    "        return f\"{x:.2f}\"\n",
    "    \n",
    "    # 5) Build each row of the table\n",
    "    rows = []\n",
    "    for label, row in summary.iterrows():\n",
    "        formatted_values = [format_value(row[col]) for col in summary.columns]\n",
    "        row_line = f\"    {label:<30} & \" + \" & \".join(f\"{val:<6}\" for val in formatted_values) + r\" \\\\\"\n",
    "        rows.append(row_line)\n",
    "    \n",
    "    body = \"\\n\".join(rows)\n",
    "    \n",
    "    # 6) Assemble the subfigure LaTeX\n",
    "    subfigure_code = r\"\"\"\\begin{subfigure}[b]{0.9\\textwidth}\n",
    "      \\centering\n",
    "      \\footnotesize\n",
    "      \\caption{Project summary statistics}\n",
    "      \\label{fig:project-summary-stats}\n",
    "      \\begin{tabular}{@{}l r *{5}{r}@{}}\n",
    "        \\toprule\n",
    "        Metric                        & Mean   & \\multicolumn{5}{c}{Percentiles} \\\\\n",
    "        \\cmidrule(lr){3-7}\n",
    "                                      &        & 10th   & 25th   & 50th   & 75th   & 90th   \\\\\n",
    "        \\midrule\n",
    "    \"\"\" + body + r\"\"\"\n",
    "        \\bottomrule\n",
    "      \\end{tabular}\n",
    "    \\end{subfigure}\"\"\"\n",
    "    \n",
    "    print(subfigure_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a906a8-d4db-4d96-a691-2dd728a562bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{subfigure}[b]{0.9\\textwidth}\n",
      "      \\centering\n",
      "      \\footnotesize\n",
      "      \\caption{Project summary statistics}\n",
      "      \\label{fig:project-summary-stats}\n",
      "      \\begin{tabular}{@{}l r *{5}{r}@{}}\n",
      "        \\toprule\n",
      "        Metric                        & Mean   & \\multicolumn{5}{c}{Percentiles} \\\\\n",
      "        \\cmidrule(lr){3-7}\n",
      "                                      &        & 10th   & 25th   & 50th   & 75th   & 90th   \\\\\n",
      "        \\midrule\n",
      "        Contributors                   & 106.34 & 9      & 20     & 49     & 119    & 239    \\\\\n",
      "    Problems                       & 204.33 & 11     & 35     & 88     & 256    & 558    \\\\\n",
      "    Unlinked issues                & 110.24 & 4      & 15     & 44     & 146    & 291    \\\\\n",
      "    Unlinked pull requests         & 73.55  & 3      & 10     & 28     & 79     & 169    \\\\\n",
      "    Linked issue–pull request pairs & 20.54  & 0      & 1      & 5      & 20     & 53     \\\\\n",
      "    Discussions per problem        & 4.03   & 2      & 2.76   & 3.67   & 4.82   & 6.46   \\\\\n",
      "    Contributors per problem       & 1.95   & 1.45   & 1.68   & 1.96   & 2.19   & 2.45   \\\\\n",
      "    Time periods per project       & 13.91  & 8      & 10     & 15     & 18     & 18     \\\\\n",
      "        \\bottomrule\n",
      "      \\end{tabular}\n",
      "    \\end{subfigure}\n"
     ]
    }
   ],
   "source": [
    "ProjectSummaryStats(df_problems_contr_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab1264e-b79d-43b2-99e8-db440f027aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_list = df_problems_contr_filtered['repo_name'].unique().tolist()\n",
    "def GetCommunicationLogs(df_contributors):\n",
    "    df_contributors['communication_log'] = df_contributors['communication_log'].apply(ast.literal_eval)\n",
    "    df_contributors['communication_log'] = df_contributors['communication_log'].apply(ConvertLogKeysToInt)\n",
    "    \n",
    "    df_contr_comm = df_contributors[['repo_name','time_period','actor_id','communication_log']]\n",
    "    df_contr_dept = df_problems_contr_filtered[['repo_name','time_period','departed_actor_id','treatment_period']].drop_duplicates()\n",
    "    df_contr_dept_comm = pd.merge(df_contr_comm, df_contr_dept)\n",
    "    df_contr_dept_comm['dept_ov_comm'] = df_contr_dept_comm.apply(\n",
    "        lambda x: x['communication_log'].get(int(x['departed_actor_id'])), axis = 1)\n",
    "\n",
    "    cooccur_counts = BuildCooccurrenceCounts(df_problems_contr_filtered)\n",
    "    \n",
    "    df_contr_dept_comm['problem_count'] = df_contr_dept_comm.apply(\n",
    "        lambda row: cooccur_counts.get(\n",
    "            (row.repo_name, row.time_period, int(float(row.actor_id)), int(float(row.departed_actor_id))), 0), axis=1)\n",
    "    df_contr_dept_comm.loc[df_contr_dept_comm['problem_count'] ==0, 'dept_ov_comm']= np.nan\n",
    "    return df_contr_dept_comm\n",
    "\n",
    "def BuildCooccurrenceCounts(df_probs):\n",
    "    \"\"\"Returns dict mapping\n",
    "       (repo_name, time_period, actor, departed_actor) → count\n",
    "       for every unordered pair in each row’s all_actors list.\"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for (_, group) in df_probs.groupby(['repo_name','time_period']):\n",
    "        repo = group.repo_name.iloc[0]\n",
    "        period = group.time_period.iloc[0]\n",
    "        for actors in group.all_actors:\n",
    "            # turn actors-list into a set to avoid dupes\n",
    "            s = set([int(float(a)) for a in actors])\n",
    "            # for every *ordered* pair of distinct actors\n",
    "            for a, b in combinations(s, 2):\n",
    "                counts[(repo, period, a, b)] += 1\n",
    "                counts[(repo, period, b, a)] += 1\n",
    "    return counts\n",
    "\n",
    "df_contributors = pd.read_parquet('drive/output/derived/graph_structure/contributor_characteristics.parquet', filters = [('repo_name',\"in\",repo_list)])\n",
    "df_contr_dept_comm = GetCommunicationLogs(df_contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0310ab74-9df3-45ea-b568-26589b8afc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pre_contr = df_contr_dept_comm[df_contr_dept_comm['time_period'] < df_contr_dept_comm['treatment_period']]\n",
    "df_pre_repo = (\n",
    "    df_pre_contr[['repo_name','time_period']].drop_duplicates()\n",
    "    .sort_values(['repo_name','time_period'], ascending=[True,False])\n",
    "    .groupby(['repo_name'], as_index=False)\n",
    "    .head(5)\n",
    ")\n",
    "df_pre_contr = pd.merge(df_pre_contr, df_pre_repo)\n",
    "\n",
    "actor_metrics = (\n",
    "    df_pre_contr\n",
    "    .groupby(['repo_name','actor_id'], as_index=False)\n",
    "    .agg(\n",
    "        agg_dept_ov_comm   = ('dept_ov_comm', 'sum'),\n",
    "        agg_problem_count     = ('problem_count',    'sum'),\n",
    "    )\n",
    ")\n",
    "actor_metrics['agg_dept_ov_comm'] = actor_metrics['agg_dept_ov_comm'].replace(0, np.nan)\n",
    "actor_metrics['agg_dept_ov_comm_per_problem'] = actor_metrics['agg_dept_ov_comm'] / actor_metrics['agg_problem_count']\n",
    "\n",
    "repo_metrics = (\n",
    "    actor_metrics.groupby('repo_name', as_index=False)\n",
    "    .agg(avg_dept_ov_comm_repo_avg = ('agg_dept_ov_comm', 'mean'),\n",
    "         avg_dept_ov_comm_per_problem_repo_avg = ('agg_dept_ov_comm_per_problem','mean'),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_actor_summary = actor_metrics.merge(repo_metrics, on='repo_name')\n",
    "df_actor_summary['actor_id'] = pd.to_numeric(df_actor_summary['actor_id'], errors='coerce')\n",
    "\n",
    "for metric in ['dept_ov_comm', 'dept_ov_comm_per_problem']:\n",
    "    agg_col  = f'agg_{metric}'\n",
    "    avg_col  = f'avg_{metric}_repo_avg'\n",
    "\n",
    "        \n",
    "    df_actor_summary[f'{metric}_2bin']   = (\n",
    "        df_actor_summary[agg_col] > df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_05avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > .5*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_2avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > 2*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_3avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > 3*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    \n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_05avg_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_2avg_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_3avg_2bin'] = np.nan\n",
    "\n",
    "    if metric == 'dept_ov_comm_per_problem':\n",
    "        df_actor_summary[[f'{metric}_min_2bin',f'{metric}_min_05avg_2bin',f'{metric}_min_2avg_2bin',f'{metric}_min_3avg_2bin']] = df_actor_summary[\n",
    "        [f'{metric}_2bin',f'{metric}_05avg_2bin',f'{metric}_2avg_2bin',f'{metric}_3avg_2bin']]\n",
    "        \n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_05avg_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_2avg_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_3avg_2bin'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc5db4a-236c-4b9e-9ada-e1da868ffa3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_contr_all = df_problems_contr_filtered[['repo_name','time_period','all_actors_period']].drop_duplicates(\n",
    "    ['repo_name','time_period']).explode('all_actors_period').rename(columns={'all_actors_period':'actor_id'}).sort_values(\n",
    "    'time_period').drop_duplicates(['repo_name','actor_id'])\n",
    "df_contr_all['actor_id'] = pd.to_numeric(df_contr_all['actor_id'])\n",
    "\n",
    "df_actor_summary = pd.merge(df_contr_all, df_actor_summary, how = 'outer')\n",
    "df_actor_summary['agg_problem_count'] = df_actor_summary['agg_problem_count'].fillna(0)\n",
    "df_actor_summary['avg_dept_ov_comm_repo_avg'] = (df_actor_summary.groupby('repo_name')['avg_dept_ov_comm_repo_avg']\n",
    "                                           .transform(lambda x: x.ffill().bfill()))\n",
    "df_actor_summary['avg_dept_ov_comm_per_problem_repo_avg'] = (df_actor_summary.groupby('repo_name')['avg_dept_ov_comm_per_problem_repo_avg']\n",
    "                                          .transform(lambda x: x.ffill().bfill()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e65652-108c-4286-a36f-81b17f3e2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_summary = pd.merge(df_actor_summary, df_contr_dept_comm[['repo_name','treatment_period']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ced33f-be4e-4624-8035-d9636ca7e113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "overview_metrics = [\n",
    "    'dept_ov_comm_2bin',\n",
    "    'dept_ov_comm_05avg_2bin',\n",
    "    'dept_ov_comm_2avg_2bin',\n",
    "    'dept_ov_comm_3avg_2bin',\n",
    "    'dept_ov_comm_per_problem_2bin',\n",
    "    'dept_ov_comm_per_problem_05avg_2bin',\n",
    "    'dept_ov_comm_per_problem_2avg_2bin',\n",
    "    'dept_ov_comm_per_problem_3avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_2bin',\n",
    "    'dept_ov_comm_per_problem_min_05avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_2avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_3avg_2bin'\n",
    "]\n",
    "status_funcs = {\n",
    "    'high': lambda s: s > 0,\n",
    "    'low':  lambda s: s == 0,\n",
    "    'never_communicated': lambda s: s.isna(),\n",
    "    'communicated':       lambda s: s.notna(),\n",
    "    'never_communicated_predep': \"\",\n",
    "}\n",
    "\n",
    "actor_frames = []\n",
    "for metric in overview_metrics:\n",
    "    for status, cond in status_funcs.items():\n",
    "        col_name = f'{status}_{metric}_actors'\n",
    "        if status == \"never_communicated_predep\":\n",
    "            df_temp = (\n",
    "                df_actor_summary[df_actor_summary[metric].isna()]\n",
    "                .query('time_period < treatment_period')\n",
    "                .groupby('repo_name')['actor_id']\n",
    "                .agg(list)\n",
    "                .reset_index()\n",
    "                .rename(columns={'actor_id': col_name})\n",
    "            )\n",
    "        else:   \n",
    "            df_temp = (\n",
    "                df_actor_summary[cond(df_actor_summary[metric])]\n",
    "                .groupby('repo_name')['actor_id']\n",
    "                .agg(list)\n",
    "                .reset_index()\n",
    "                .rename(columns={'actor_id': col_name})\n",
    "            )\n",
    "        actor_frames.append(df_temp)\n",
    "\n",
    "df_actor_lists = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on='repo_name', how='outer'),\n",
    "    actor_frames\n",
    ")\n",
    "\n",
    "for metric in overview_metrics:\n",
    "    for status in status_funcs:\n",
    "        col = f'{status}_{metric}_actors'\n",
    "        df_actor_lists[col] = df_actor_lists[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "df_pr_issues      = df_problems_contr_filtered[\n",
    "    df_problems_contr_filtered['type'].isin(['linked', 'unlinked pr'])\n",
    "]\n",
    "df_pr_with_actors = pd.merge(df_pr_issues, df_actor_lists, on='repo_name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea8fb80e-3c51-4e59-b6a8-15613426bb6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_map = {'high': 'above',\n",
    " 'low': 'below',\n",
    " 'never_communicated': 'never_comm',\n",
    " 'communicated': 'comm',\n",
    "             'never_communicated_predep':'never_comm_predep'}\n",
    "metric_map = {\n",
    "    'dept_ov_comm_2bin': 'dept_comm_avg',\n",
    "    'dept_ov_comm_05avg_2bin': 'dept_comm_05avg',\n",
    "    'dept_ov_comm_2avg_2bin': 'dept_comm_2avg',\n",
    "    'dept_ov_comm_3avg_2bin': 'dept_comm_3avg',\n",
    "    'dept_ov_comm_per_problem_2bin': 'dept_comm_per_problem_avg',\n",
    "    'dept_ov_comm_per_problem_05avg_2bin': 'dept_comm_per_problem_05avg',\n",
    "    'dept_ov_comm_per_problem_2avg_2bin': 'dept_comm_per_problem_2avg',\n",
    "    'dept_ov_comm_per_problem_3avg_2bin': 'dept_comm_per_problem_3avg',\n",
    "    'dept_ov_comm_per_problem_min_2bin': 'dept_comm_per_problem_min_avg',\n",
    "    'dept_ov_comm_per_problem_min_05avg_2bin': 'dept_comm_per_problem_min_05avg',\n",
    "    'dept_ov_comm_per_problem_min_2avg_2bin': 'dept_comm_per_problem_min_2avg',\n",
    "    'dept_ov_comm_per_problem_min_3avg_2bin': 'dept_comm_per_problem_min_3avg',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c5e384-750e-461f-90b6-7e457c7c0da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dept_ov_comm_2bin high\n",
      "0.18061269468116367 27224\n",
      "dept_ov_comm_2bin low\n",
      "0.5871381387215854 10294\n",
      "dept_ov_comm_05avg_2bin high\n",
      "0.13193969587444238 30711\n",
      "dept_ov_comm_05avg_2bin low\n",
      "0.6872149477710755 6797\n",
      "dept_ov_comm_2avg_2bin high\n",
      "0.2793149615084235 17926\n",
      "dept_ov_comm_2avg_2bin low\n",
      "0.42900888026947026 19594\n",
      "dept_ov_comm_3avg_2bin high\n",
      "0.32818456684632574 15214\n",
      "dept_ov_comm_3avg_2bin low\n",
      "0.3611746245236494 22305\n",
      "dept_ov_comm_per_problem_2bin high\n",
      "0.4024080596281432 12209\n",
      "dept_ov_comm_per_problem_2bin low\n",
      "0.2246462730218955 25302\n",
      "dept_ov_comm_per_problem_05avg_2bin high\n",
      "0.11754555912090574 33034\n",
      "dept_ov_comm_per_problem_05avg_2bin low\n",
      "0.6235162374020157 4465\n",
      "dept_ov_comm_per_problem_2avg_2bin high\n",
      "0.5971830985915493 1065\n",
      "dept_ov_comm_per_problem_2avg_2bin low\n",
      "0.02929467644071054 36423\n",
      "dept_ov_comm_per_problem_3avg_2bin high\n",
      "0.7982456140350878 114\n",
      "dept_ov_comm_per_problem_3avg_2bin low\n",
      "0.0004549468782615677 37367\n",
      "dept_ov_comm_per_problem_min_2bin high\n",
      "0.36587992461635105 11143\n",
      "dept_ov_comm_per_problem_min_2bin low\n",
      "0.2029719369646491 21131\n",
      "dept_ov_comm_per_problem_min_05avg_2bin high\n",
      "0.07765494137353433 29850\n",
      "dept_ov_comm_per_problem_min_05avg_2bin low\n",
      "0.5640812940688511 2411\n",
      "dept_ov_comm_per_problem_min_2avg_2bin high\n",
      "0.532608695652174 736\n",
      "dept_ov_comm_per_problem_min_2avg_2bin low\n",
      "0.02132114981915096 31518\n",
      "dept_ov_comm_per_problem_min_3avg_2bin high\n",
      "0.6 5\n",
      "dept_ov_comm_per_problem_min_3avg_2bin low\n",
      "0.0 32248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df_comm_wide_ov = PivotAndFlattenCommSummary(\\n    df_pr_with_actors, match_col='all_actors', overview_metrics=overview_metrics, base_status=['high', 'low'], \\n    special_status=['never_communicated', 'communicated'], metric_map=metric_map, status_map=status_map)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- your existing actor-list build (unchanged) ---\n",
    "def SummarizeMetricStatus(df, metric, status, match_col    ):\n",
    "    actor_col = f'{status}_{metric}_actors'\n",
    "    df[actor_col] = df[actor_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    mask = df.apply(\n",
    "        lambda row: (\n",
    "            row['departed_actor_id'] not in row['all_actors']\n",
    "            and bool(set(row[match_col]) & set(row[actor_col]))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    df_filtered = df[mask].drop_duplicates(\n",
    "        ['repo_name','problem_id']).query('type != \"unlinked issue\"')\n",
    "    \n",
    "    summary = (\n",
    "        df_filtered\n",
    "        .groupby(['repo_name', 'time_period'])\n",
    "        .apply(lambda grp: pd.Series({\n",
    "            'prs_opened_count': len(grp),\n",
    "            'contributor_count': len(set().union(*grp[actor_col].tolist(), *grp['all_actors_period'].tolist()))\n",
    "        }))\n",
    "        .reset_index()\n",
    "    )\n",
    "    if status in ['low','high']:\n",
    "        opp_status = 'high' if status == 'low' else 'low'\n",
    "        opp_actor_col = f'{opp_status}_{metric}_actors'\n",
    "        opp_mask = df_filtered.apply(lambda row: (row['departed_actor_id'] not in row['all_actors']\n",
    "                                         and bool(set(row['all_actors']) & set(row[opp_actor_col]))),\n",
    "                            axis=1)\n",
    "        subset_opp_involved = df_filtered[opp_mask]\n",
    "        print(metric, status)\n",
    "        print(subset_opp_involved.shape[0]/df_filtered.shape[0], df_filtered.shape[0])\n",
    "        \n",
    "    summary['overview_metric'] = metric\n",
    "    summary['status'] = status\n",
    "    return summary\n",
    "\n",
    "\n",
    "def PivotAndFlattenCommSummary(df_pr_with_actors, match_col, overview_metrics, base_status, \n",
    "                               special_status, metric_map, status_map):\n",
    "    summaries = [\n",
    "        SummarizeMetricStatus(df_pr_with_actors, m, s, match_col)\n",
    "        for m in overview_metrics for s in base_status\n",
    "    ] + [\n",
    "        SummarizeMetricStatus(df_pr_with_actors, overview_metrics[0], s, match_col)\n",
    "        for s in special_status\n",
    "    ]\n",
    "    df_comm_summary = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    df_wide = (\n",
    "        df_comm_summary\n",
    "        .pivot_table(\n",
    "            index=['repo_name', 'time_period'],\n",
    "            columns=['overview_metric', 'status'],\n",
    "            values=['prs_opened_count', 'contributor_count'],\n",
    "            fill_value=0\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    flat_columns = []\n",
    "    for col in df_wide.columns:\n",
    "        if isinstance(col, tuple):\n",
    "            if all(col) and len(col) == 3:\n",
    "                metric_type, metric_name, status = col\n",
    "                flat_prefix = 'prs_opened' if metric_type == 'prs_opened_count' else 'contributors'\n",
    "                mname = metric_map[metric_name]\n",
    "                sname = status_map[status]\n",
    "                flat_columns.append(f'{flat_prefix}_{mname}_{sname}')\n",
    "            else:\n",
    "                flat_columns.append(col[0])\n",
    "        else:\n",
    "            flat_columns.append(col)\n",
    "\n",
    "    df_wide.columns = flat_columns\n",
    "\n",
    "    return df_wide.rename(columns={\n",
    "        'prs_opened_dept_comm_avg_comm':           'prs_opened_dept_comm',\n",
    "        'prs_opened_dept_comm_avg_never_comm':     'prs_opened_dept_never_comm',\n",
    "        'prs_opened_dept_comm_avg_never_comm_predep':     'prs_opened_dept_never_comm_predep',\n",
    "        'contributors_dept_comm_avg_comm':         'contributors_dept_comm',\n",
    "        'contributors_dept_comm_avg_never_comm':   'contributors_dept_never_comm',\n",
    "        'contributors_dept_comm_avg_never_comm_predep':   'contributors_dept_never_comm_predep',\n",
    "    })\n",
    "\n",
    "df_comm_wide = PivotAndFlattenCommSummary(\n",
    "    df_pr_with_actors, match_col='pr_opener', overview_metrics=overview_metrics, base_status=['high', 'low'], \n",
    "    special_status=['never_communicated', 'communicated', 'never_communicated_predep'], metric_map=metric_map, status_map=status_map)\n",
    "\"\"\"df_comm_wide_ov = PivotAndFlattenCommSummary(\n",
    "    df_pr_with_actors, match_col='all_actors', overview_metrics=overview_metrics, base_status=['high', 'low'], \n",
    "    special_status=['never_communicated', 'communicated'], metric_map=metric_map, status_map=status_map)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0669239b-7819-4a3d-ade8-3bf080fc1a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2246462730218955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4024080596281432\n",
    "0.2246462730218955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57f160a5-7bed-4b57-8cda-9622ec9683ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# people are involved int wice as much activity as they're opening \\nfor avg in ['avg','2avg','3avg']:\\n    sel_cols = [f'prs_opened_dept_comm_{avg}_above',f'prs_opened_dept_comm_{avg}_below']\\n    print(df_comm_wide_ov[sel_cols].sum().sum()/df_comm_wide[sel_cols].sum().sum())\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# people are involved int wice as much activity as they're opening \n",
    "for avg in ['avg','2avg','3avg']:\n",
    "    sel_cols = [f'prs_opened_dept_comm_{avg}_above',f'prs_opened_dept_comm_{avg}_below']\n",
    "    print(df_comm_wide_ov[sel_cols].sum().sum()/df_comm_wide[sel_cols].sum().sum())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f59bfc96-72a1-4c5e-b0fd-5d9a5b90e357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_problems_contr_filtered['unimp_actors'] = df_problems_contr_filtered.apply(\n",
    "    lambda row: [actor for actor in row['all_actors'] if actor not in row['important_actors_rolling']], axis=1)\n",
    "df_problems_contr_filtered['problem_unimp_contr_count'] = df_problems_contr_filtered['unimp_actors'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a21a90-d9ad-4808-b8c2-4e7e8d7d3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributors = df_problems_contr_filtered[['repo_name','time_period','treatment_period','all_actors_period','departed_actor_id']].explode('all_actors_period').sort_values(['repo_name','time_period'])\n",
    "df_project_predeparture_contributors = df_contributors.query('time_period < treatment_period & departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_predeparture_contributors = df_project_predeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_pre_departure'})\n",
    "df_project_nondeparture_contributors = df_contributors.query('departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_nondeparture_contributors = df_project_nondeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_non_departure'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdda3090-2502-45f6-9442-e8cb6e803fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_problems_contr_filtered_predep = pd.merge(df_problems_contr_filtered, df_project_predeparture_contributors)\n",
    "df_problems_contr_filtered_predep = df_problems_contr_filtered_predep.loc[\n",
    "    df_problems_contr_filtered_predep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_pre_departure']).size, axis=1)\n",
    "]\n",
    "df_problems_contr_filtered_nondep = pd.merge(df_problems_contr_filtered, df_project_nondeparture_contributors)\n",
    "df_problems_contr_filtered_nondep = df_problems_contr_filtered_nondep.loc[\n",
    "    df_problems_contr_filtered_nondep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_non_departure']).size, axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d6ba81-750d-45ef-a179-faf5268e91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_problems_contr_filtered['contributions_dict'] = df_problems_contr_filtered['contributions_dict'].apply(ast.literal_eval)\n",
    "df_problems_contr_filtered['contributions_dict'] = (df_problems_contr_filtered['contributions_dict'].apply(lambda d: {float(k): v for k, v in d.items()}))\n",
    "df_problems_contr_filtered['total_contributions'] = (df_problems_contr_filtered['contributions_dict'].apply(\n",
    "    lambda contributions_dict: sum(item['contributions'] for key, item in contributions_dict.items()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eeec488-fd49-4eb5-81c0-ed47a184f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_predep = df_problems_contr_filtered_predep.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_predep'})\n",
    "\n",
    "df_agg_nondep = df_problems_contr_filtered_nondep.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_nondep'})\n",
    "\n",
    "df_agg_prob = df_problems_contr_filtered.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_prob'})\n",
    "\n",
    "df_agg_prs = pd.merge(df_agg_predep, df_agg_nondep, how = 'outer').merge(df_comm_wide, how = 'outer').merge(df_agg_prob, how = 'outer')\n",
    "\n",
    "\n",
    "df_problem_contr_count = df_problems_contr_filtered.query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])[['problem_contr_count','problem_unimp_contr_count']].mean().reset_index().rename(\n",
    "    columns={'problem_contr_count':'problem_avg_contr_count', 'problem_unimp_contr_count':'problem_avg_unimp_contr_count'})\n",
    "df_problem_close_time_contr = df_problems_contr_filtered.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])[['close_time','total_contributions']].mean().reset_index()\n",
    "df_agg_prs = pd.merge(df_agg_prs, df_problem_contr_count, how = 'outer').merge(df_problem_close_time_contr, how = 'outer')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59a294a2-dc2a-4646-a962-b12dc5619e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_problems_contr_filtered['important_contributions_share'] = (df_problems_contr_filtered.apply(\n",
    "    lambda d: sum(v['contributions'] for k, v in d['contributions_dict'].items() if k in d['important_actors_rolling']), axis = 1) / \n",
    "                                                 df_problems_contr_filtered['total_contributions'])\n",
    "df_imp_share = df_problems_contr_filtered.query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])[['important_contributions_share']].mean().reset_index()\n",
    "df_agg_prs = pd.merge(df_agg_prs, df_imp_share, how = 'outer')#.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d84582b-7d70-49aa-a13f-e866b4a075eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comment_grouped = (\n",
    "    df_problems_contr_filtered\n",
    "    .sort_values(['repo_name', 'problem_id_num', 'time_period'])\n",
    "    .drop_duplicates(['repo_name', 'problem_id'])\n",
    "    .query('type != \"unlinked issue\"')\n",
    "    .groupby(['repo_name', 'time_period'])\n",
    "    .agg(\n",
    "        review_count=('review_count', 'mean'),\n",
    "        review_comment_count=('review_comment_count', 'mean'),\n",
    "        prop_review_count_na=('review_count', lambda x: x.isna().mean()),\n",
    "        prop_review_comment_count_na=('review_comment_count', lambda x: x.isna().mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_agg_prs = pd.merge(df_agg_prs, df_comment_grouped, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca1c2e5f-3ae2-4794-90e3-f4c70dd18795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>time_period</th>\n",
       "      <th>prs_opened_prob</th>\n",
       "      <th>prs_opened_predep</th>\n",
       "      <th>prs_opened_nondep</th>\n",
       "      <th>prs_opened_dept_comm</th>\n",
       "      <th>prs_opened_dept_never_comm</th>\n",
       "      <th>prs_opened_dept_never_comm_predep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>105.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>183.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>166.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>195.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>284.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>284.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>283.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>121.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>92.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EpistasisLab/tpot</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo_name time_period  prs_opened_prob  \\\n",
       "0               AnalogJ/lexicon  2016-01-01             33.0   \n",
       "1               AnalogJ/lexicon  2016-07-01             27.0   \n",
       "2               AnalogJ/lexicon  2017-01-01             35.0   \n",
       "3               AnalogJ/lexicon  2017-07-01             17.0   \n",
       "4               AnalogJ/lexicon  2018-01-01             49.0   \n",
       "5               AnalogJ/lexicon  2018-07-01             45.0   \n",
       "6               AnalogJ/lexicon  2019-01-01             51.0   \n",
       "7               AnalogJ/lexicon  2019-07-01             37.0   \n",
       "8               AnalogJ/lexicon  2020-01-01             25.0   \n",
       "9               AnalogJ/lexicon  2020-07-01             17.0   \n",
       "10              AnalogJ/lexicon  2021-01-01             19.0   \n",
       "11              AnalogJ/lexicon  2021-07-01             38.0   \n",
       "12              AnalogJ/lexicon  2022-01-01             45.0   \n",
       "13              AnalogJ/lexicon  2022-07-01             32.0   \n",
       "14              AnalogJ/lexicon  2023-01-01             14.0   \n",
       "15              AnalogJ/lexicon  2023-07-01              4.0   \n",
       "16  Cog-Creators/Red-DiscordBot  2017-07-01            105.0   \n",
       "17  Cog-Creators/Red-DiscordBot  2018-01-01            183.0   \n",
       "18  Cog-Creators/Red-DiscordBot  2018-07-01            131.0   \n",
       "19  Cog-Creators/Red-DiscordBot  2019-01-01            166.0   \n",
       "20  Cog-Creators/Red-DiscordBot  2019-07-01            195.0   \n",
       "21  Cog-Creators/Red-DiscordBot  2020-01-01            284.0   \n",
       "22  Cog-Creators/Red-DiscordBot  2020-07-01            284.0   \n",
       "23  Cog-Creators/Red-DiscordBot  2021-01-01            283.0   \n",
       "24  Cog-Creators/Red-DiscordBot  2021-07-01            107.0   \n",
       "25  Cog-Creators/Red-DiscordBot  2022-01-01            121.0   \n",
       "26  Cog-Creators/Red-DiscordBot  2022-07-01             60.0   \n",
       "27  Cog-Creators/Red-DiscordBot  2023-01-01             92.0   \n",
       "28  Cog-Creators/Red-DiscordBot  2023-07-01             23.0   \n",
       "29            EpistasisLab/tpot  2018-01-01             10.0   \n",
       "\n",
       "    prs_opened_predep  prs_opened_nondep  prs_opened_dept_comm  \\\n",
       "0                 3.0                3.0                   0.0   \n",
       "1                 5.0                5.0                   1.0   \n",
       "2                13.0               13.0                   6.0   \n",
       "3                 3.0                3.0                   2.0   \n",
       "4                 6.0                6.0                   4.0   \n",
       "5                 1.0                1.0                   1.0   \n",
       "6                 5.0                5.0                   5.0   \n",
       "7                10.0               10.0                   7.0   \n",
       "8                18.0               28.0                  20.0   \n",
       "9                 5.0               17.0                   2.0   \n",
       "10                4.0               19.0                   1.0   \n",
       "11               19.0               38.0                   0.0   \n",
       "12               35.0               45.0                   2.0   \n",
       "13               19.0               32.0                   0.0   \n",
       "14               10.0               14.0                   0.0   \n",
       "15                1.0                4.0                   0.0   \n",
       "16               99.0               99.0                  71.0   \n",
       "17              129.0              129.0                 100.0   \n",
       "18               74.0               74.0                  63.0   \n",
       "19               89.0               89.0                  80.0   \n",
       "20              114.0              114.0                 102.0   \n",
       "21              230.0              230.0                 201.0   \n",
       "22              279.0              279.0                 209.0   \n",
       "23              235.0              286.0                 169.0   \n",
       "24               79.0              108.0                  51.0   \n",
       "25               93.0              121.0                  84.0   \n",
       "26               48.0               61.0                  33.0   \n",
       "27               74.0               92.0                  64.0   \n",
       "28               20.0               23.0                  15.0   \n",
       "29                1.0                1.0                   0.0   \n",
       "\n",
       "    prs_opened_dept_never_comm  prs_opened_dept_never_comm_predep  \n",
       "0                          3.0                                3.0  \n",
       "1                          4.0                                4.0  \n",
       "2                          7.0                                7.0  \n",
       "3                          1.0                                1.0  \n",
       "4                          2.0                                2.0  \n",
       "5                          0.0                                0.0  \n",
       "6                          0.0                                0.0  \n",
       "7                          3.0                                2.0  \n",
       "8                          8.0                                3.0  \n",
       "9                         15.0                                1.0  \n",
       "10                        15.0                                0.0  \n",
       "11                        19.0                                1.0  \n",
       "12                        12.0                                0.0  \n",
       "13                        13.0                                0.0  \n",
       "14                         5.0                                1.0  \n",
       "15                         4.0                                0.0  \n",
       "16                        28.0                               28.0  \n",
       "17                        27.0                               27.0  \n",
       "18                        10.0                               10.0  \n",
       "19                         8.0                                8.0  \n",
       "20                        14.0                               14.0  \n",
       "21                        28.0                               23.0  \n",
       "22                        68.0                               57.0  \n",
       "23                       113.0                               60.0  \n",
       "24                        52.0                               25.0  \n",
       "25                        36.0                               12.0  \n",
       "26                        27.0                               11.0  \n",
       "27                        22.0                                3.0  \n",
       "28                         7.0                                1.0  \n",
       "29                         1.0                                1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_prs[['repo_name','time_period','prs_opened_prob','prs_opened_predep','prs_opened_nondep',\n",
    "            'prs_opened_dept_comm','prs_opened_dept_never_comm','prs_opened_dept_never_comm_predep']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e426e79c-6462-4e07-8e79-44f927083c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to leave alone\n",
    "exclude = {'close_time', 'prop_review_comment_count_na', 'prop_review_count_na'}\n",
    "\n",
    "# build a dict mapping every other column to 0\n",
    "fill_values = {col: 0 for col in df_agg_prs.columns if col not in exclude}\n",
    "\n",
    "# apply the fill\n",
    "df_agg_prs = df_agg_prs.fillna(fill_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1348b4d5-f100-4839-bef4-1912bccff440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'issue/project_collaboration.parquet' saved successfully.\n"
     ]
    }
   ],
   "source": [
    "preperiod_recent = df_project_filtered_group.query('time_period < treatment_period').groupby('repo_name').tail(5)\n",
    "preperiod_recent['other_involved_count'] = preperiod_recent['departed_involved_count'] - preperiod_recent['problem_count']\n",
    "preperiod_recent['uniform_weight'] = 1\n",
    "\n",
    "count_dict = {\n",
    "    'ind_collab': 'problem_count',\n",
    "    'ind_key_collab': 'departed_involved_count',\n",
    "    'ind_other_collab': 'other_involved_count',\n",
    "    'departed_involved': 'problem_count',\n",
    "    'departed_involved_count': 'uniform_weight',\n",
    "    'key_contributor_count': 'uniform_weight',\n",
    "    'total_contributor_count': 'uniform_weight',\n",
    "    'problem_count': 'uniform_weight',\n",
    "    'departed_opened': 'departed_opened_count',\n",
    "    'departed_authored': 'departed_authored_count'\n",
    "}\n",
    "\n",
    "for collab_type, count_col in count_dict.items():\n",
    "    avg_collab = WeightedMean(preperiod_recent[collab_type], preperiod_recent[count_col])\n",
    "    base_wm = preperiod_recent.groupby('repo_name').apply(\n",
    "        lambda df: WeightedMean(df[collab_type], df[count_col], zero_weight_return = 0)\n",
    "    )\n",
    "\n",
    "    above_set = set(base_wm[base_wm > avg_collab].index)\n",
    "    df_project_filtered_group[f\"{collab_type}_2bin\"] = df_project_filtered_group['repo_name'].apply(lambda x: int(x in above_set))\n",
    "\n",
    "df_project_filtered_group = df_project_filtered_group.merge(df_agg_prs, how = 'left')\n",
    "df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']] = df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']].fillna(0)\n",
    "\n",
    "from source.lib.JMSLab.SaveData import SaveData\n",
    "SaveData(df_project_filtered_group, [\"repo_name\",\"time_period\"],\n",
    "         'issue/project_collaboration.parquet',\n",
    "         'issue/project_collaboration.log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234432a8-2ca4-4336-ab69-633d429417d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
