{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7353ca-7a0a-49bf-b138-d7ea242d1972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252286ad-d984-4fb0-8e31-b0da5354bee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from source.lib.helpers import *\n",
    "from pandarallel import pandarallel\n",
    "import ast\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac22f5f-f1a9-425a-b0af-6c29cf722dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightedQuantile(values, weights, quantiles):\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    sorter = np.argsort(values)\n",
    "    values = values[sorter]\n",
    "    weights = weights[sorter]\n",
    "    cumulative_weight = np.cumsum(weights)\n",
    "    total_weight = cumulative_weight[-1]\n",
    "    return np.interp(np.array(quantiles) * total_weight, cumulative_weight, values)\n",
    "\n",
    "def Assign3Bin(repo):\n",
    "    val = base_wm[repo]\n",
    "    if val <= q33:\n",
    "        return 0\n",
    "    elif val <= q67:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def ConvertLogKeysToInt(log_dict):\n",
    "    return {int(float(key)): value for key, value in log_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97954a0d-146a-419d-9ade-65fcd5762c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_problems_contr_filtered = pd.read_parquet('issue/filtered_problem_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a906a8-d4db-4d96-a691-2dd728a562bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectLevelStats(df_problems_contr_filtered):\n",
    "    # controls that I can add down the road\n",
    "    # % of problems that are unlinked prs/linked\n",
    "    df_problems_contr_filtered['departed_involved'] = df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['all_actors'], axis = 1)\n",
    "    df_problems_contr_filtered['key_contributor_count'] = df_problems_contr_filtered['important_actors_rolling'].apply(len)\n",
    "    df_problems_contr_filtered['total_contributor_count'] = df_problems_contr_filtered['all_actors_period'].apply(len)\n",
    "    df_problems_contr_filtered['departed_opener'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_opener'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "    df_problems_contr_filtered['departed_author'] = pd.to_numeric(df_problems_contr_filtered.apply(lambda x: x['departed_actor_id'] in x['pr_authors'] if x['departed_involved'] else np.nan, axis = 1))\n",
    "    \n",
    "    df_project_filtered_group = df_problems_contr_filtered.groupby(\n",
    "        ['repo_name', 'time_period', 'treatment_period', 'key_contributor_count', 'total_contributor_count']\n",
    "    ).agg(\n",
    "        problem_count=('problem_id', 'count'),\n",
    "        ind_collab=('ind_collab_roll', 'mean'),\n",
    "        ind_key_collab=('ind_key_collab_roll', 'mean'),\n",
    "        ind_other_collab=('ind_other_collab_roll', 'mean'),\n",
    "        departed_involved_count=('departed_involved','sum'),\n",
    "        departed_involved=('departed_involved','mean'),\n",
    "        departed_opened_count=('departed_opener','sum'),\n",
    "        departed_opened=('departed_opener','mean'), # conditional on involvement\n",
    "        departed_authored_count=('departed_author','sum'),\n",
    "        departed_authored=('departed_author','mean'), # conditional on involvement\n",
    "    ).reset_index()\n",
    "    return df_project_filtered_group\n",
    "\n",
    "df_project_filtered_group = ProjectLevelStats(df_problems_contr_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab1264e-b79d-43b2-99e8-db440f027aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_list = df_problems_contr_filtered['repo_name'].unique().tolist()\n",
    "def GetCommunicationLogs(df_contributors):\n",
    "    df_contributors['communication_log'] = df_contributors['communication_log'].apply(ast.literal_eval)\n",
    "    df_contributors['communication_log'] = df_contributors['communication_log'].apply(ConvertLogKeysToInt)\n",
    "    \n",
    "    df_contr_comm = df_contributors[['repo_name','time_period','actor_id','communication_log']]\n",
    "    df_contr_dept = df_problems_contr_filtered[['repo_name','time_period','departed_actor_id','treatment_period']].drop_duplicates()\n",
    "    df_contr_dept_comm = pd.merge(df_contr_comm, df_contr_dept)\n",
    "    df_contr_dept_comm['dept_ov_comm'] = df_contr_dept_comm.apply(\n",
    "        lambda x: x['communication_log'].get(int(x['departed_actor_id'])), axis = 1)\n",
    "\n",
    "    cooccur_counts = BuildCooccurrenceCounts(df_problems_contr_filtered)\n",
    "    \n",
    "    df_contr_dept_comm['problem_count'] = df_contr_dept_comm.apply(\n",
    "        lambda row: cooccur_counts.get(\n",
    "            (row.repo_name, row.time_period, int(float(row.actor_id)), int(float(row.departed_actor_id))), 0), axis=1)\n",
    "    df_contr_dept_comm.loc[df_contr_dept_comm['problem_count'] ==0, 'dept_ov_comm']= np.nan\n",
    "    return df_contr_dept_comm\n",
    "\n",
    "def BuildCooccurrenceCounts(df_probs):\n",
    "    \"\"\"Returns dict mapping\n",
    "       (repo_name, time_period, actor, departed_actor) → count\n",
    "       for every unordered pair in each row’s all_actors list.\"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    for (_, group) in df_probs.groupby(['repo_name','time_period']):\n",
    "        repo = group.repo_name.iloc[0]\n",
    "        period = group.time_period.iloc[0]\n",
    "        for actors in group.all_actors:\n",
    "            # turn actors-list into a set to avoid dupes\n",
    "            s = set([int(float(a)) for a in actors])\n",
    "            # for every *ordered* pair of distinct actors\n",
    "            for a, b in combinations(s, 2):\n",
    "                counts[(repo, period, a, b)] += 1\n",
    "                counts[(repo, period, b, a)] += 1\n",
    "    return counts\n",
    "\n",
    "df_contributors = pd.read_parquet('drive/output/derived/graph_structure/contributor_characteristics.parquet', filters = [('repo_name',\"in\",repo_list)])\n",
    "df_contr_dept_comm = GetCommunicationLogs(df_contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0310ab74-9df3-45ea-b568-26589b8afc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pre_contr = df_contr_dept_comm[df_contr_dept_comm['time_period'] < df_contr_dept_comm['treatment_period']]\n",
    "df_pre_repo = (\n",
    "    df_pre_contr[['repo_name','time_period']].drop_duplicates()\n",
    "    .sort_values(['repo_name','time_period'], ascending=[True,False])\n",
    "    .groupby(['repo_name'], as_index=False)\n",
    "    .head(5)\n",
    ")\n",
    "df_pre_contr = pd.merge(df_pre_contr, df_pre_repo)\n",
    "\n",
    "actor_metrics = (\n",
    "    df_pre_contr\n",
    "    .groupby(['repo_name','actor_id'], as_index=False)\n",
    "    .agg(\n",
    "        agg_dept_ov_comm   = ('dept_ov_comm', 'sum'),\n",
    "        agg_problem_count     = ('problem_count',    'sum'),\n",
    "    )\n",
    ")\n",
    "actor_metrics['agg_dept_ov_comm'] = actor_metrics['agg_dept_ov_comm'].replace(0, np.nan)\n",
    "actor_metrics['agg_dept_ov_comm_per_problem'] = actor_metrics['agg_dept_ov_comm'] / actor_metrics['agg_problem_count']\n",
    "\n",
    "repo_metrics = (\n",
    "    actor_metrics.groupby('repo_name', as_index=False)\n",
    "    .agg(avg_dept_ov_comm_repo_avg = ('agg_dept_ov_comm', 'mean'),\n",
    "         avg_dept_ov_comm_per_problem_repo_avg = ('agg_dept_ov_comm_per_problem','mean'),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_actor_summary = actor_metrics.merge(repo_metrics, on='repo_name')\n",
    "df_actor_summary['actor_id'] = pd.to_numeric(df_actor_summary['actor_id'], errors='coerce')\n",
    "\n",
    "for metric in ['dept_ov_comm', 'dept_ov_comm_per_problem']:\n",
    "    agg_col  = f'agg_{metric}'\n",
    "    avg_col  = f'avg_{metric}_repo_avg'\n",
    "\n",
    "        \n",
    "    df_actor_summary[f'{metric}_2bin']   = (\n",
    "        df_actor_summary[agg_col] > df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_05avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > .5*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_2avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > 2*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    df_actor_summary[f'{metric}_3avg_2bin']   = (\n",
    "        df_actor_summary[agg_col] > 3*df_actor_summary[avg_col]\n",
    "    ).astype(int)\n",
    "    \n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_05avg_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_2avg_2bin'] = np.nan\n",
    "    df_actor_summary.loc[df_actor_summary[agg_col].isna(), f'{metric}_3avg_2bin'] = np.nan\n",
    "\n",
    "    if metric == 'dept_ov_comm_per_problem':\n",
    "        df_actor_summary[[f'{metric}_min_2bin',f'{metric}_min_05avg_2bin',f'{metric}_min_2avg_2bin',f'{metric}_min_3avg_2bin']] = df_actor_summary[\n",
    "        [f'{metric}_2bin',f'{metric}_05avg_2bin',f'{metric}_2avg_2bin',f'{metric}_3avg_2bin']]\n",
    "        \n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_05avg_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_2avg_2bin'] = np.nan\n",
    "        df_actor_summary.loc[df_actor_summary['agg_problem_count']<5, f'{metric}_min_3avg_2bin'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fc5db4a-236c-4b9e-9ada-e1da868ffa3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_contr_all = df_problems_contr_filtered[['repo_name','time_period','all_actors_period']].drop_duplicates(\n",
    "    ['repo_name','time_period']).explode('all_actors_period').rename(columns={'all_actors_period':'actor_id'}).sort_values(\n",
    "    'time_period').drop_duplicates(['repo_name','actor_id'])\n",
    "df_contr_all['actor_id'] = pd.to_numeric(df_contr_all['actor_id'])\n",
    "\n",
    "df_actor_summary = pd.merge(df_contr_all, df_actor_summary, how = 'outer')\n",
    "df_actor_summary['agg_problem_count'] = df_actor_summary['agg_problem_count'].fillna(0)\n",
    "df_actor_summary['avg_dept_ov_comm_repo_avg'] = (df_actor_summary.groupby('repo_name')['avg_dept_ov_comm_repo_avg']\n",
    "                                           .transform(lambda x: x.ffill().bfill()))\n",
    "df_actor_summary['avg_dept_ov_comm_per_problem_repo_avg'] = (df_actor_summary.groupby('repo_name')['avg_dept_ov_comm_per_problem_repo_avg']\n",
    "                                          .transform(lambda x: x.ffill().bfill()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07e65652-108c-4286-a36f-81b17f3e2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actor_summary = pd.merge(df_actor_summary, df_contr_dept_comm[['repo_name','treatment_period']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1ced33f-be4e-4624-8035-d9636ca7e113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "overview_metrics = [\n",
    "    'dept_ov_comm_2bin',\n",
    "    'dept_ov_comm_05avg_2bin',\n",
    "    'dept_ov_comm_2avg_2bin',\n",
    "    'dept_ov_comm_3avg_2bin',\n",
    "    'dept_ov_comm_per_problem_2bin',\n",
    "    'dept_ov_comm_per_problem_05avg_2bin',\n",
    "    'dept_ov_comm_per_problem_2avg_2bin',\n",
    "    'dept_ov_comm_per_problem_3avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_2bin',\n",
    "    'dept_ov_comm_per_problem_min_05avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_2avg_2bin',\n",
    "    'dept_ov_comm_per_problem_min_3avg_2bin'\n",
    "]\n",
    "status_funcs = {\n",
    "    'high': lambda s: s > 0,\n",
    "    'low':  lambda s: s == 0,\n",
    "    'never_communicated': lambda s: s.isna(),\n",
    "    'communicated':       lambda s: s.notna(),\n",
    "    'never_communicated_predep': \"\",\n",
    "}\n",
    "\n",
    "actor_frames = []\n",
    "for metric in overview_metrics:\n",
    "    for status, cond in status_funcs.items():\n",
    "        col_name = f'{status}_{metric}_actors'\n",
    "        if status == \"never_communicated_predep\":\n",
    "            df_temp = (\n",
    "                df_actor_summary[df_actor_summary[metric].isna()]\n",
    "                .query('time_period < treatment_period')\n",
    "                .groupby('repo_name')['actor_id']\n",
    "                .agg(list)\n",
    "                .reset_index()\n",
    "                .rename(columns={'actor_id': col_name})\n",
    "            )\n",
    "        else:   \n",
    "            df_temp = (\n",
    "                df_actor_summary[cond(df_actor_summary[metric])]\n",
    "                .groupby('repo_name')['actor_id']\n",
    "                .agg(list)\n",
    "                .reset_index()\n",
    "                .rename(columns={'actor_id': col_name})\n",
    "            )\n",
    "        actor_frames.append(df_temp)\n",
    "\n",
    "df_actor_lists = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on='repo_name', how='outer'),\n",
    "    actor_frames\n",
    ")\n",
    "\n",
    "for metric in overview_metrics:\n",
    "    for status in status_funcs:\n",
    "        col = f'{status}_{metric}_actors'\n",
    "        df_actor_lists[col] = df_actor_lists[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "df_pr_issues      = df_problems_contr_filtered[\n",
    "    df_problems_contr_filtered['type'].isin(['linked', 'unlinked pr'])\n",
    "]\n",
    "df_pr_with_actors = pd.merge(df_pr_issues, df_actor_lists, on='repo_name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea8fb80e-3c51-4e59-b6a8-15613426bb6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_map = {'high': 'above',\n",
    " 'low': 'below',\n",
    " 'never_communicated': 'never_comm',\n",
    " 'communicated': 'comm',\n",
    "             'never_communicated_predep':'never_comm_predep'}\n",
    "metric_map = {\n",
    "    'dept_ov_comm_2bin': 'dept_comm_avg',\n",
    "    'dept_ov_comm_05avg_2bin': 'dept_comm_05avg',\n",
    "    'dept_ov_comm_2avg_2bin': 'dept_comm_2avg',\n",
    "    'dept_ov_comm_3avg_2bin': 'dept_comm_3avg',\n",
    "    'dept_ov_comm_per_problem_2bin': 'dept_comm_per_problem_avg',\n",
    "    'dept_ov_comm_per_problem_05avg_2bin': 'dept_comm_per_problem_05avg',\n",
    "    'dept_ov_comm_per_problem_2avg_2bin': 'dept_comm_per_problem_2avg',\n",
    "    'dept_ov_comm_per_problem_3avg_2bin': 'dept_comm_per_problem_3avg',\n",
    "    'dept_ov_comm_per_problem_min_2bin': 'dept_comm_per_problem_min_avg',\n",
    "    'dept_ov_comm_per_problem_min_05avg_2bin': 'dept_comm_per_problem_min_05avg',\n",
    "    'dept_ov_comm_per_problem_min_2avg_2bin': 'dept_comm_per_problem_min_2avg',\n",
    "    'dept_ov_comm_per_problem_min_3avg_2bin': 'dept_comm_per_problem_min_3avg',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0c5e384-750e-461f-90b6-7e457c7c0da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dept_ov_comm_2bin high\n",
      "0.14045547319798046 37236\n",
      "dept_ov_comm_2bin low\n",
      "0.5181714471968709 12272\n",
      "dept_ov_comm_05avg_2bin high\n",
      "0.10529123623842088 41238\n",
      "dept_ov_comm_05avg_2bin low\n",
      "0.5944800871565186 8261\n",
      "dept_ov_comm_2avg_2bin high\n",
      "0.2126938775510204 24500\n",
      "dept_ov_comm_2avg_2bin low\n",
      "0.3505278310940499 25008\n",
      "dept_ov_comm_3avg_2bin high\n",
      "0.2506403750422889 20691\n",
      "dept_ov_comm_3avg_2bin low\n",
      "0.2919211549139367 28816\n",
      "dept_ov_comm_per_problem_2bin high\n",
      "0.28794642857142855 17920\n",
      "dept_ov_comm_per_problem_2bin low\n",
      "0.17089469517022962 31575\n",
      "dept_ov_comm_per_problem_05avg_2bin high\n",
      "0.09707805569527642 43738\n",
      "dept_ov_comm_per_problem_05avg_2bin low\n",
      "0.5317336115458181 5751\n",
      "dept_ov_comm_per_problem_2avg_2bin high\n",
      "0.4561911658218682 1381\n",
      "dept_ov_comm_per_problem_2avg_2bin low\n",
      "0.022497141074955818 48095\n",
      "dept_ov_comm_per_problem_3avg_2bin high\n",
      "0.6814814814814815 135\n",
      "dept_ov_comm_per_problem_3avg_2bin low\n",
      "0.0002837799489196092 49334\n",
      "dept_ov_comm_per_problem_min_2bin high\n",
      "0.25478175576262874 16312\n",
      "dept_ov_comm_per_problem_min_2bin low\n",
      "0.14966605950212508 26352\n",
      "dept_ov_comm_per_problem_min_05avg_2bin high\n",
      "0.06334750050597045 39528\n",
      "dept_ov_comm_per_problem_min_05avg_2bin low\n",
      "0.48945012787723785 3128\n",
      "dept_ov_comm_per_problem_min_2avg_2bin high\n",
      "0.41007194244604317 973\n",
      "dept_ov_comm_per_problem_min_2avg_2bin low\n",
      "0.01624436126307707 41676\n",
      "dept_ov_comm_per_problem_min_3avg_2bin high\n",
      "0.3333333333333333 6\n",
      "dept_ov_comm_per_problem_min_3avg_2bin low\n",
      "0.0 42642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"df_comm_wide_ov = PivotAndFlattenCommSummary(\\n    df_pr_with_actors, match_col='all_actors', overview_metrics=overview_metrics, base_status=['high', 'low'], \\n    special_status=['never_communicated', 'communicated'], metric_map=metric_map, status_map=status_map)\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- your existing actor-list build (unchanged) ---\n",
    "def SummarizeMetricStatus(df, metric, status, match_col    ):\n",
    "    actor_col = f'{status}_{metric}_actors'\n",
    "    df[actor_col] = df[actor_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    mask = df.apply(\n",
    "        lambda row: (\n",
    "            row['departed_actor_id'] not in row['all_actors']\n",
    "            and bool(set(row[match_col]) & set(row[actor_col]))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    df_filtered = df[mask].drop_duplicates(\n",
    "        ['repo_name','problem_id']).query('type != \"unlinked issue\"')\n",
    "    \n",
    "    summary = (\n",
    "        df_filtered\n",
    "        .groupby(['repo_name', 'time_period'])\n",
    "        .apply(lambda grp: pd.Series({\n",
    "            'prs_opened_count': len(grp),\n",
    "            'contributor_count': len(set().union(*grp[actor_col].tolist(), *grp['all_actors_period'].tolist()))\n",
    "        }))\n",
    "        .reset_index()\n",
    "    )\n",
    "    if status in ['low','high']:\n",
    "        opp_status = 'high' if status == 'low' else 'low'\n",
    "        opp_actor_col = f'{opp_status}_{metric}_actors'\n",
    "        opp_mask = df_filtered.apply(lambda row: (row['departed_actor_id'] not in row['all_actors']\n",
    "                                         and bool(set(row['all_actors']) & set(row[opp_actor_col]))),\n",
    "                            axis=1)\n",
    "        subset_opp_involved = df_filtered[opp_mask]\n",
    "        print(metric, status)\n",
    "        print(subset_opp_involved.shape[0]/df_filtered.shape[0], df_filtered.shape[0])\n",
    "        \n",
    "    summary['overview_metric'] = metric\n",
    "    summary['status'] = status\n",
    "    return summary\n",
    "\n",
    "\n",
    "def PivotAndFlattenCommSummary(df_pr_with_actors, match_col, overview_metrics, base_status, \n",
    "                               special_status, metric_map, status_map):\n",
    "    summaries = [\n",
    "        SummarizeMetricStatus(df_pr_with_actors, m, s, match_col)\n",
    "        for m in overview_metrics for s in base_status\n",
    "    ] + [\n",
    "        SummarizeMetricStatus(df_pr_with_actors, overview_metrics[0], s, match_col)\n",
    "        for s in special_status\n",
    "    ]\n",
    "    df_comm_summary = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    df_wide = (\n",
    "        df_comm_summary\n",
    "        .pivot_table(\n",
    "            index=['repo_name', 'time_period'],\n",
    "            columns=['overview_metric', 'status'],\n",
    "            values=['prs_opened_count', 'contributor_count'],\n",
    "            fill_value=0\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    flat_columns = []\n",
    "    for col in df_wide.columns:\n",
    "        if isinstance(col, tuple):\n",
    "            if all(col) and len(col) == 3:\n",
    "                metric_type, metric_name, status = col\n",
    "                flat_prefix = 'prs_opened' if metric_type == 'prs_opened_count' else 'contributors'\n",
    "                mname = metric_map[metric_name]\n",
    "                sname = status_map[status]\n",
    "                flat_columns.append(f'{flat_prefix}_{mname}_{sname}')\n",
    "            else:\n",
    "                flat_columns.append(col[0])\n",
    "        else:\n",
    "            flat_columns.append(col)\n",
    "\n",
    "    df_wide.columns = flat_columns\n",
    "\n",
    "    return df_wide.rename(columns={\n",
    "        'prs_opened_dept_comm_avg_comm':           'prs_opened_dept_comm',\n",
    "        'prs_opened_dept_comm_avg_never_comm':     'prs_opened_dept_never_comm',\n",
    "        'prs_opened_dept_comm_avg_never_comm_predep':     'prs_opened_dept_never_comm_predep',\n",
    "        'contributors_dept_comm_avg_comm':         'contributors_dept_comm',\n",
    "        'contributors_dept_comm_avg_never_comm':   'contributors_dept_never_comm',\n",
    "        'contributors_dept_comm_avg_never_comm_predep':   'contributors_dept_never_comm_predep',\n",
    "    })\n",
    "\n",
    "df_comm_wide = PivotAndFlattenCommSummary(\n",
    "    df_pr_with_actors, match_col='pr_opener', overview_metrics=overview_metrics, base_status=['high', 'low'], \n",
    "    special_status=['never_communicated', 'communicated', 'never_communicated_predep'], metric_map=metric_map, status_map=status_map)\n",
    "\"\"\"df_comm_wide_ov = PivotAndFlattenCommSummary(\n",
    "    df_pr_with_actors, match_col='all_actors', overview_metrics=overview_metrics, base_status=['high', 'low'], \n",
    "    special_status=['never_communicated', 'communicated'], metric_map=metric_map, status_map=status_map)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57f160a5-7bed-4b57-8cda-9622ec9683ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# people are involved int wice as much activity as they're opening \\nfor avg in ['avg','2avg','3avg']:\\n    sel_cols = [f'prs_opened_dept_comm_{avg}_above',f'prs_opened_dept_comm_{avg}_below']\\n    print(df_comm_wide_ov[sel_cols].sum().sum()/df_comm_wide[sel_cols].sum().sum())\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# people are involved int wice as much activity as they're opening \n",
    "for avg in ['avg','2avg','3avg']:\n",
    "    sel_cols = [f'prs_opened_dept_comm_{avg}_above',f'prs_opened_dept_comm_{avg}_below']\n",
    "    print(df_comm_wide_ov[sel_cols].sum().sum()/df_comm_wide[sel_cols].sum().sum())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73a21a90-d9ad-4808-b8c2-4e7e8d7d3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributors = df_problems_contr_filtered[['repo_name','time_period','treatment_period','all_actors_period','departed_actor_id']].explode('all_actors_period').sort_values(['repo_name','time_period'])\n",
    "df_project_predeparture_contributors = df_contributors.query('time_period < treatment_period & departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_predeparture_contributors = df_project_predeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_pre_departure'})\n",
    "df_project_nondeparture_contributors = df_contributors.query('departed_actor_id != all_actors_period').drop_duplicates(['repo_name','all_actors_period'])\n",
    "df_project_nondeparture_contributors = df_project_nondeparture_contributors.groupby(['repo_name'])['all_actors_period'].agg(list).reset_index().rename(columns={'all_actors_period':'all_actors_non_departure'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdda3090-2502-45f6-9442-e8cb6e803fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_problems_contr_filtered_predep = pd.merge(df_problems_contr_filtered, df_project_predeparture_contributors)\n",
    "df_problems_contr_filtered_predep = df_problems_contr_filtered_predep.loc[\n",
    "    df_problems_contr_filtered_predep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_pre_departure']).size, axis=1)\n",
    "]\n",
    "df_problems_contr_filtered_nondep = pd.merge(df_problems_contr_filtered, df_project_nondeparture_contributors)\n",
    "df_problems_contr_filtered_nondep = df_problems_contr_filtered_nondep.loc[\n",
    "    df_problems_contr_filtered_nondep.apply(lambda row: row['all_actors'].size == np.intersect1d(row['all_actors'], row['all_actors_non_departure']).size, axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0eeec488-fd49-4eb5-81c0-ed47a184f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_predep = df_problems_contr_filtered_predep.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_predep'})\n",
    "\n",
    "df_agg_nondep = df_problems_contr_filtered_nondep.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_nondep'})\n",
    "\n",
    "df_agg_prob = df_problems_contr_filtered.sort_values(['repo_name','problem_id_num','time_period']).drop_duplicates(\n",
    "    ['repo_name','problem_id']).query('type != \"unlinked issue\"').groupby(\n",
    "    ['repo_name','time_period'])['problem_id'].count().reset_index().rename(columns={'problem_id':'prs_opened_prob'})\n",
    "\n",
    "df_agg_prs = pd.merge(df_agg_predep, df_agg_nondep, how = 'outer').merge(df_comm_wide, how = 'outer').fillna(0).merge(df_agg_prob, how = 'outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca1c2e5f-3ae2-4794-90e3-f4c70dd18795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>time_period</th>\n",
       "      <th>prs_opened_prob</th>\n",
       "      <th>prs_opened_predep</th>\n",
       "      <th>prs_opened_nondep</th>\n",
       "      <th>prs_opened_dept_comm</th>\n",
       "      <th>prs_opened_dept_never_comm</th>\n",
       "      <th>prs_opened_dept_never_comm_predep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>53.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AnalogJ/lexicon</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>230.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>404.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>271.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>330.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>282.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>512.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>345.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>325.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>225.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>183.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>94.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>187.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cog-Creators/Red-DiscordBot</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EpistasisLab/tpot</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      repo_name time_period  prs_opened_prob  \\\n",
       "0               AnalogJ/lexicon  2016-01-01             38.0   \n",
       "1               AnalogJ/lexicon  2016-07-01             27.0   \n",
       "2               AnalogJ/lexicon  2017-01-01             43.0   \n",
       "3               AnalogJ/lexicon  2017-07-01             17.0   \n",
       "4               AnalogJ/lexicon  2018-01-01             58.0   \n",
       "5               AnalogJ/lexicon  2018-07-01             55.0   \n",
       "6               AnalogJ/lexicon  2019-01-01             57.0   \n",
       "7               AnalogJ/lexicon  2019-07-01             40.0   \n",
       "8               AnalogJ/lexicon  2020-01-01             37.0   \n",
       "9               AnalogJ/lexicon  2020-07-01             21.0   \n",
       "10              AnalogJ/lexicon  2021-01-01             26.0   \n",
       "11              AnalogJ/lexicon  2021-07-01             49.0   \n",
       "12              AnalogJ/lexicon  2022-01-01             53.0   \n",
       "13              AnalogJ/lexicon  2022-07-01             36.0   \n",
       "14              AnalogJ/lexicon  2023-01-01             21.0   \n",
       "15              AnalogJ/lexicon  2023-07-01             11.0   \n",
       "16  Cog-Creators/Red-DiscordBot  2017-07-01            230.0   \n",
       "17  Cog-Creators/Red-DiscordBot  2018-01-01            404.0   \n",
       "18  Cog-Creators/Red-DiscordBot  2018-07-01            271.0   \n",
       "19  Cog-Creators/Red-DiscordBot  2019-01-01            330.0   \n",
       "20  Cog-Creators/Red-DiscordBot  2019-07-01            282.0   \n",
       "21  Cog-Creators/Red-DiscordBot  2020-01-01            512.0   \n",
       "22  Cog-Creators/Red-DiscordBot  2020-07-01            345.0   \n",
       "23  Cog-Creators/Red-DiscordBot  2021-01-01            325.0   \n",
       "24  Cog-Creators/Red-DiscordBot  2021-07-01            225.0   \n",
       "25  Cog-Creators/Red-DiscordBot  2022-01-01            183.0   \n",
       "26  Cog-Creators/Red-DiscordBot  2022-07-01             94.0   \n",
       "27  Cog-Creators/Red-DiscordBot  2023-01-01            187.0   \n",
       "28  Cog-Creators/Red-DiscordBot  2023-07-01             31.0   \n",
       "29            EpistasisLab/tpot  2018-01-01             17.0   \n",
       "\n",
       "    prs_opened_predep  prs_opened_nondep  prs_opened_dept_comm  \\\n",
       "0                 8.0                8.0                   5.0   \n",
       "1                 5.0                5.0                   1.0   \n",
       "2                20.0               20.0                  13.0   \n",
       "3                 3.0                3.0                   2.0   \n",
       "4                 9.0                9.0                   4.0   \n",
       "5                 3.0                3.0                   1.0   \n",
       "6                11.0               11.0                   7.0   \n",
       "7                 9.0                9.0                   6.0   \n",
       "8                21.0               40.0                  23.0   \n",
       "9                10.0               21.0                   6.0   \n",
       "10               10.0               26.0                   7.0   \n",
       "11               30.0               49.0                   2.0   \n",
       "12               43.0               53.0                   6.0   \n",
       "13               22.0               36.0                   1.0   \n",
       "14               13.0               21.0                   2.0   \n",
       "15                7.0               11.0                   6.0   \n",
       "16              224.0              224.0                 167.0   \n",
       "17              303.0              303.0                 247.0   \n",
       "18              180.0              180.0                 164.0   \n",
       "19              227.0              227.0                 212.0   \n",
       "20              174.0              174.0                 162.0   \n",
       "21              411.0              411.0                 379.0   \n",
       "22              335.0              335.0                 247.0   \n",
       "23              270.0              328.0                 194.0   \n",
       "24               99.0              227.0                  59.0   \n",
       "25              121.0              183.0                 105.0   \n",
       "26               72.0               96.0                  44.0   \n",
       "27              113.0              187.0                  95.0   \n",
       "28               27.0               31.0                  21.0   \n",
       "29                3.0                3.0                   0.0   \n",
       "\n",
       "    prs_opened_dept_never_comm  prs_opened_dept_never_comm_predep  \n",
       "0                          3.0                                3.0  \n",
       "1                          4.0                                4.0  \n",
       "2                          7.0                                7.0  \n",
       "3                          1.0                                1.0  \n",
       "4                          2.0                                2.0  \n",
       "5                          0.0                                0.0  \n",
       "6                          0.0                                0.0  \n",
       "7                          3.0                                2.0  \n",
       "8                         17.0                                3.0  \n",
       "9                         15.0                                1.0  \n",
       "10                        16.0                                0.0  \n",
       "11                        19.0                                1.0  \n",
       "12                        12.0                                0.0  \n",
       "13                        14.0                                0.0  \n",
       "14                         7.0                                0.0  \n",
       "15                         5.0                                0.0  \n",
       "16                        35.0                               35.0  \n",
       "17                        42.0                               42.0  \n",
       "18                        10.0                               10.0  \n",
       "19                        12.0                               12.0  \n",
       "20                        12.0                               12.0  \n",
       "21                        28.0                               23.0  \n",
       "22                        79.0                               68.0  \n",
       "23                       121.0                               64.0  \n",
       "24                       151.0                               28.0  \n",
       "25                        71.0                               13.0  \n",
       "26                        45.0                               14.0  \n",
       "27                        80.0                                5.0  \n",
       "28                         9.0                                1.0  \n",
       "29                         2.0                                2.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_prs[['repo_name','time_period','prs_opened_prob','prs_opened_predep','prs_opened_nondep',\n",
    "            'prs_opened_dept_comm','prs_opened_dept_never_comm','prs_opened_dept_never_comm_predep']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1348b4d5-f100-4839-bef4-1912bccff440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preperiod_recent = df_project_filtered_group.query('time_period < treatment_period').groupby('repo_name').tail(5)\n",
    "preperiod_recent['other_involved_count'] = preperiod_recent['departed_involved_count'] - preperiod_recent['problem_count']\n",
    "preperiod_recent['uniform_weight'] = 1\n",
    "\n",
    "count_dict = {\n",
    "    'ind_collab': 'problem_count',\n",
    "    'ind_key_collab': 'departed_involved_count',\n",
    "    'ind_other_collab': 'other_involved_count',\n",
    "    'departed_involved': 'problem_count',\n",
    "    'departed_involved_count': 'uniform_weight',\n",
    "    'key_contributor_count': 'uniform_weight',\n",
    "    'total_contributor_count': 'uniform_weight',\n",
    "    'problem_count': 'uniform_weight',\n",
    "    'departed_opened': 'departed_opened_count',\n",
    "    'departed_authored': 'departed_authored_count'\n",
    "}\n",
    "\n",
    "for collab_type, count_col in count_dict.items():\n",
    "    avg_collab = WeightedMean(preperiod_recent[collab_type], preperiod_recent[count_col])\n",
    "    base_wm = preperiod_recent.groupby('repo_name').apply(\n",
    "        lambda df: WeightedMean(df[collab_type], df[count_col], zero_weight_return = 0)\n",
    "    )\n",
    "\n",
    "    above_set = set(base_wm[base_wm > avg_collab].index)\n",
    "    df_project_filtered_group[f\"{collab_type}_2bin\"] = df_project_filtered_group['repo_name'].apply(lambda x: int(x in above_set))\n",
    "\n",
    "    # 3-bin: weighted quantiles\n",
    "    q33, q67 = WeightedQuantile(preperiod_recent[collab_type], preperiod_recent[count_col], [0.33, 0.67])\n",
    "\n",
    "    df_project_filtered_group[f\"{collab_type}_3bin\"] = df_project_filtered_group['repo_name'].apply(Assign3Bin)\n",
    "\n",
    "df_project_filtered_group = df_project_filtered_group.merge(df_agg_prs, how = 'left')\n",
    "df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']] = df_project_filtered_group[['prs_opened_predep','prs_opened_nondep']].fillna(0)\n",
    "df_project_filtered_group.to_parquet('issue/project_collaboration.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f0e39-613a-4395-8480-61f480da1ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
