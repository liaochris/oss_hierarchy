{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735be759-b891-4c68-99e7-ecc10a0de56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff2fff1-4ade-4150-8c3d-2fcbacf65884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import warnings\n",
    "import random\n",
    "from glob import glob \n",
    "import datetime\n",
    "import itertools\n",
    "import time\n",
    "from multiprocessing import pool\n",
    "from source.lib.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495fdc61-e9f0-4aee-884e-4cc8333a6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir_abandoned = Path('drive/output/derived/project_outcomes/abandoned_projects')\n",
    "indir_departures = Path('drive/output/derived/contributor_stats/departed_contributors')\n",
    "outdir_departures_filtered = Path('drive/output/derived/contributor_stats/filtered_departed_contributors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740a33a5-52b7-4f09-8fc6-6402698524b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FilterSpecification(df_specification, idx, time_period, rolling_window, indir_departures, indir_abandoned, outdir_departures_filtered,\n",
    "                        contribution_histories):\n",
    "    criteria_pct = df_specifications.loc[idx,'criteria_pct']\n",
    "    consecutive_periods = df_specifications.loc[idx,'consecutive_periods']\n",
    "    post_period_length = df_specifications.loc[idx,'post_period_length']\n",
    "    decline_type = df_specifications.loc[idx,'decline_type']\n",
    "    decline_stat = df_specifications.loc[idx,'decline_stat']\n",
    "    if decline_stat == 0 or decline_type == \"threshold_gap_qty\":\n",
    "        decline_stat = int(decline_stat)\n",
    "    \n",
    "    df_departed = pd.read_parquet(indir_departures / f'departed_contributors_major_months{time_period}_window{rolling_window}D_criteria_commits_{criteria_pct}pct_consecutive{consecutive_periods}_post_period{post_period_length}_{decline_type}_{decline_stat}.parquet')\n",
    "    df_departure_range = CleanDepartures(df_departed, decline_type)\n",
    "    df_departure_range = LabelScrapedAbandonment(df_departure_range, indir_abandoned)\n",
    "    df_departure_range = LabelDataExtractedAbandonment(df_departure_range, indir_abandoned, time_period)\n",
    "    \n",
    "    df_departure_range['repo_count'] = df_departure_range.groupby('repo_name')['actor_id'].transform('count')\n",
    "    df_departure_range['last_pre_period'] = df_departure_range['time_range'].apply(lambda x: x[0])\n",
    "    df_departure_range['treatment_period'] = df_departure_range['time_range'].apply(lambda x: x[1])\n",
    "    \n",
    "    df_departure_range = FilterOutStillParticipating(df_departure_range, contribution_histories)\n",
    "    df_departure_range.to_parquet(outdir_departures_filtered / f'filtered_departed_contributors_major_months{time_period}_window{rolling_window}D_criteria_commits_{criteria_pct}pct_consecutive{consecutive_periods}_post_period{post_period_length}_{decline_type}_{decline_stat}.parquet')\n",
    "\n",
    "    return df_departure_range\n",
    "\n",
    "def CleanDepartures(df_departed, decline_type):\n",
    "    if decline_type == \"threshold_gap_qty\":\n",
    "        df_departed = df_departed.query('below_qty_mean_gap0 == 1')\n",
    "\n",
    "    df_departed = pd.merge(df_departed, df_departed.query('time_period == final_period')\\\n",
    "                           [['repo_name','actor_id','grouped_index']].rename({'grouped_index':'final_index'}, axis = 1))\n",
    "    if decline_type == \"threshold_gap_qty\":\n",
    "        df_departed['final_index'] = df_departed.apply(\n",
    "            lambda x: x['final_index'] if x['below_qty_mean_gap0'] == 1 else x['final_index']+1, axis = 1)\n",
    "    df_departed = pd.merge(df_departed.drop('final_period', axis = 1), df_departed.query('grouped_index == final_index')[['actor_id','repo_name','time_period']]\\\n",
    "                          .rename({'time_period':'final_period'}, axis = 1))\n",
    "    df_departed['first_post_period_index'] = df_departed['final_index'] + 1\n",
    "    df_departed['relative_time'] = (df_departed['grouped_index'] - df_departed['final_index'])-1\n",
    "\n",
    "        \n",
    "    df_departed['time_period'] = pd.to_datetime(df_departed['time_period'])\n",
    "    df_departure_range = df_departed.query('relative_time == -1 | relative_time == 0')\\\n",
    "        .groupby(['repo_name','actor_id']).agg({'time_period':list}).reset_index()\n",
    "    df_departure_range['time_range'] = df_departure_range['time_period'].apply(lambda x: [x[0].date(), x[1].date()])\n",
    "    df_departure_range = df_departure_range.drop('time_period', axis = 1) \n",
    "    return df_departure_range\n",
    "\n",
    "def LabelScrapedAbandonment(df_departure_range, indir_abandoned):\n",
    "    df_abandoned_scraped = pd.read_csv(indir_abandoned / 'scraped_abandoned_repo_data.csv', index_col = 0).query('status == \"abandoned\"')\n",
    "    df_abandoned_scraped['abandoned_date'] = pd.to_datetime(df_abandoned_scraped['abandoned_date']).apply(lambda x: x.date())\n",
    "    \n",
    "    df_departure_range = pd.merge(df_departure_range, df_abandoned_scraped[['repo_name','abandoned_date']], how = 'left')\n",
    "    df_departure_range['abandoned_scraped'] = df_departure_range.apply(\n",
    "            lambda x: not pd.isnull(x['abandoned_date']) and x['time_range'][0]<=x['abandoned_date']<=x['time_range'][1], axis = 1)\n",
    "    return df_departure_range\n",
    "\n",
    "def LabelDataExtractedAbandonment(df_departure_range, indir_abandoned, time_period):\n",
    "    for consecutive in [2, 3, 4]:\n",
    "        for permanent in [True, False]:\n",
    "            df_abandoned_data = pd.read_parquet(indir_abandoned / f'abandoned_projects_consecutive_req{consecutive}_permanent{permanent}.parquet')\n",
    "            df_abandoned_data['abandoned_date'] = pd.to_datetime(df_abandoned_data['abandoned_date']).apply(lambda x: x.date())\n",
    "            abandoned_date_col = f'abandoned_date_consecutive_req{consecutive}_permanent{permanent}'\n",
    "            df_departure_range = pd.merge(df_departure_range, \n",
    "                                          df_abandoned_data.rename({'abandoned_date':abandoned_date_col}, axis = 1), how = 'left')\n",
    "            df_departure_range[f'abandoned_consecutive_req{consecutive}_permanent{permanent}'] = df_departure_range.apply(\n",
    "                lambda x: not pd.isnull(x[abandoned_date_col]) and x[abandoned_date_col] == x['time_range'][1], axis = 1)\n",
    "            for periods_after in [1, 2, 3]:\n",
    "                df_departure_range[f'abandoned_within_{periods_after}periods_consecutive_req{consecutive}_permanent{permanent}'] = df_departure_range.apply(\n",
    "                    lambda x: not pd.isnull(x[abandoned_date_col]) and x[abandoned_date_col] <= (x['time_range'][1] + pd.DateOffset(months=periods_after*time_period)).date(), axis = 1)\n",
    "    \n",
    "    return df_departure_range\n",
    "\n",
    "def FilterOutStillParticipating(df_departure_range, contribution_histories):\n",
    "    contribution_departure = pd.merge(contribution_histories, df_departure_range[['repo_name','actor_id','treatment_period']])\n",
    "    present_one_after = contribution_departure.query('time_period>treatment_period')[['repo_name','actor_id']].drop_duplicates().assign(present_one_after = 1)\n",
    "    present_after = contribution_departure.query('time_period>=treatment_period')[['repo_name','actor_id']].drop_duplicates().assign(present_after = 1)\n",
    "    df_departure_range = pd.merge(df_departure_range, present_one_after, how = 'left').merge(present_after, how = 'left')\n",
    "    df_departure_range[['present_one_after','present_after']] = df_departure_range[['present_one_after','present_after']].fillna(0)\n",
    "    return df_departure_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a26580-c170-44c4-a5b0-4bb779fa2d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 732\n",
      "6 1828\n",
      "CPU times: user 1min 15s, sys: 5.64 s, total: 1min 20s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for time_period in [6]: #[2,3,6]:\n",
    "    for rolling_window in [732, 1828]:\n",
    "        print(time_period, rolling_window)\n",
    "        contribution_histories = pd.read_parquet(f'drive/output/derived/contributor_stats/contributor_data/major_contributors_major_months{time_period}_window{rolling_window}D_samplefull.parquet')\n",
    "        df_specifications = pd.read_csv(indir_departures / f'departed_contributors_specification_summary_major_months{time_period}_window{rolling_window}D.csv').query('criteria_col == \"commits\"')\n",
    "        for idx in df_specifications.index:\n",
    "            df_departure_range = FilterSpecification(df_specifications, idx, time_period, rolling_window, indir_departures, indir_abandoned, outdir_departures_filtered,\n",
    "                                                     contribution_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0217c4f7-d187-459a-a962-88172d60679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out abandoned projects\n",
    "# mark projects that ARE one repo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
